{"question": "What is the primary challenge addressed by the introduction of the Linked WikiText-2 dataset?", "answer": "The primary challenge addressed is incorporating factual knowledge into language models due to difficulty in obtaining training data that describes which entities or facts each token is referring to.", "type": "text-only", "evidence": "\"...one of the primary barriers to incorporating factual knowledge into language models is that training data is hard to obtain. Standard language modeling corpora consist only of text, and thus are unable to describe which entities or facts each token is referring to.\""}
{"question": "What is the top-1 accuracy of the Oracle KGLM on birthdate prediction?", "answer": "The top-1 accuracy of the Oracle KGLM on birthdate prediction is 65%.", "type": "multimodal-t", "evidence": "The table lists the top-1/top-5 accuracy for each category and the Oracle KGLM's top-1 accuracy for birthdate prediction is specifically listed as 65."}
{"question": "How many documents are there in the training set of the Linked WikiText-2 Corpus?", "answer": "There are 600 documents in the training set.", "type": "multimodal-t", "evidence": "The information is directly listed in the table under the 'Train' column for 'Documents.'"}
{"question": "Which language model has the lowest Perplexity (PPL) according to Table 3?", "answer": "KGLM has the lowest Perplexity (PPL) with a score of 44.1.", "type": "multimodal-t", "evidence": "The PPL column indicates the perplexity scores for different language models, and KGLM shows the lowest score among them, which is clearly visible in the table."}
{"question": "Who is the last author of the paper?", "answer": "Sameer Singh", "type": "meta-data", "evidence": ""}
{"question": "On which page does the paper introduce the corpus statistics?", "answer": "Page 5", "type": "meta-data", "evidence": ""}
{"question": "How many time does the paper mention WikiText-2?", "answer": "31", "type": "meta-data", "evidence": ""}