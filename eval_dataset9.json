[
    {
        "question": "What is the top-1 accuracy of the Oracle KGLM on birthdate prediction?",
        "ground_truth": "The top-1 accuracy of the Oracle KGLM on birthdate prediction is 65%.",
        "answer": "The Oracle KGLM's top-1 accuracy on birthdate prediction is 100%. This means that when Oracle KGLM is tasked with predicting a birthdate, it can do so with 100% accuracy, indicating that it correctly identifies the entity for the given date every time it is used in this context.",
        "contexts": [
            "examine the ﬁrst token generated by eachlanguage model to determine whether it is correct.Table 4 presents performance of each languagemodel on the relations. The oracle KGLM is giventhe correct entity annotation for X, while the NELKGLM uses the discriminative model used for im-portance sampling combined with the NEL entitylinker to produce an entity annotation for X.Amongst models trained on the same data, bothKGLM variants signiﬁcantly outperform AWD-LSTM; they produce accurate facts, while AWD-LSTM produced generic, common words. KGLMsare also competitive with models trained on ordersof magnitude more data, producing factual com-pletions that require speciﬁc knowledge, such asbirthplaces, dates, and authors. However, they donot capture facts or relations that frequently appearin large corpora, like the cities within states.3 It isencouraging to see that the KGLM with automaticlinking performs comparably to oracle linking.We provide examples in Table 5 to highlightqualitative differences between KGLM, trained on600 documents, and the recent state-of-the-art lan-guage model, GPT-2, trained on the WebText cor-pus with over 8 million documents (Radford et al.,2019). For examples that both models get factu-ally correct or incorrect, the generated tokens byKGLM are often much more speciﬁc, as opposedto selection of more popular/generic tokens (GPT-2often predicts “New York” as the birthplace, evenfor popular entities). KGLM, in particular, getsfactual statements correct when the head or tail en-tities are rare, while GPT-2 can only complete factsfor more-popular entities while using more-generictokens (such as “January” instead of “20”).3This is not a failure of the KG, but of the model’s abilityto pick the correct relation from the KG given the prompt.\f5969Input SentenceGoldGPT-2KGLMBoth correctParis Hilton was born inNew York CityNew1981Arnold Schwarzenegger was born on1947-07-30July30KGLM correctBob Dylan was born inDuluthNewDuluthBarack Obama was born"
        ]
    },
    {
        "question": "How many categories of aggression were participants asked to classify texts into?",
        "ground_truth": "3 categories: overt aggression, covert aggression, and non-aggression.",
        "answer": "Participants were tasked with classifying texts into three categories: overt aggression, covert aggression, and non-aggression. The task was language-agnostic, allowing participants to choose between English or Hindi. The goal was to evaluate their ability to distinguish between different forms of aggression and non-aggression.",
        "contexts": [
            "or the individuals’ actions were considered thoseof the group and became the locus of attack. As such it was not feasible to distinguish between theindividual and group attack in lot of instances while annotating the dataset. The distinction that we madewas related to the “locus” of attack and included such targets as gender, religion, caste, country of origin,race, etc. This classiﬁcation, on the one hand, gave scope for focusing on different kinds of attack (forexample, racial attacks or communal attacks) and, on the other hand, each of these targets may actuallybe attacked using a different set of vocabulary, thereby, making these more natural classes that could beclassiﬁed using the surface-level linguistic features. Of course, it cannot be denied that these targets arenot mutually exclusive and, as such, it makes the problem not just a multi-class classiﬁcation problembut also multi-label classiﬁcation problem. In addition to this, we also make use of a different terminol-\f3ogy taking into account its use within socio-pragmatics. This was done with an understanding that hugeamount of literature within the ﬁeld of aggression and impoliteness studies might be able to contributeand provide insights to understanding the phenomenon in a better way.The aim of this shared task was much simpler than the one discussed in the previous para. It onlyinvolved classiﬁcation of the texts into 3 categories - overt aggression, covert aggression and non-aggression. We wanted to use the dataset for experimenting with different approaches to make the mosttop-level classiﬁcation of aggression on social media.3Task Setup and ScheduleThe participants interested in competing in the shared task were required to register using a Google Form.The form gave them an option to participate for either English or Hindi or both the languages. All theregistered participants were sent the links to the annotated dataset in the language(s) of their choice, alongwith a description of the format of"
        ]
    },
    {
        "question": "Based on Figure 2, which language exhibited the greatest bias in accuracy between stereotypical and non-stereotypical gender roles when using Google Translate?",
        "ground_truth": "HE (Hebrew) exhibited the greatest bias in accuracy between stereotypical and non-stereotypical gender roles when using Google Translate, with an accuracy of 76% for stereotypical roles and 38% for non-stereotypical roles, resulting in a difference of 38 percentage points.",
        "answer": "The language that showed the greatest bias in accuracy between stereotypical and non-stereotypical gender roles when using Google Translate is the one where the stereotypical gender role performed significantly better than the non-stereotypical one, as demonstrated by Zhao et al. (2018). However, without specific data on each language's performance, it's impossible to determine which language specifically showed the greatest bias. The analysis was done across all tested languages, and the performance differences were consistent. Therefore, the language that showed the greatest bias would be the one where the stereotypical gender role performed significantly better than the non-stereotypical one.",
        "contexts": [
            "most tellingly, ∆S measures the differ-\f1682ESFRITRUUKHEARDE2040608010067805244467660694654303335384457Accuracy (%)StereotypicalNon-StereotypicalFigure 2: Google Translate’s performance on gender translation on our tested languages. The performance on thestereotypical portion of WinoMT is consistently better than that on the non-stereotypical portion. The other MTsystems we tested display similar trends.Original+Adj∆ES53.163.5+10.4RU37.748.9+11.2UK38.442.9+4.5Table 4: Performance of Google Translate on Spanish,Russian, and Ukranian gender prediction accuracy (%correct) on the original WinoMT corpus, versus a mod-iﬁed version of the dataset where we add sterotypicalgender adjectives (see Section 3.3).ence in performance (F1 score) between stereo-typical and non-stereotypical gender role assign-ments, as deﬁned by Zhao et al. (2018) whouse statistics provided by the US Department ofLabor.6This metric shows that all tested sys-tems have a signiﬁcant and consistently better per-formance when presented with pro-stereotypicalassignments (e.g., a female nurse), while theirperformance deteriorates when translating anti-stereotypical roles (e.g., a male receptionist).For instance, Figure 2 depicts Google Trans-late absolute accuracies on stereotypical and non-stereotypical gender roles across all tested lan-guages. Other tested systems show similar trends.3.3Fighting Bias with BiasFinally, we tested whether we can affect thetranslations by automatically creating a versionof WinoMT with the adjectives “handsome” and“pretty” prepended to male and female entities, re-spectively. For example, the sentence in Figure 1will be converted to: “The pretty doctor asked thenurse to help her in the operation”. We are inter-ested in evaluating whether this “corrects” the pro-fession bias by mixing signals, e.g., while “doc-6https://www.bls.gov/cps/cpsaat11.htmtor” biases towards a male translation, “pretty”tugs the translation towards a female inﬂection.Our results show that this"
        ]
    },
    {
        "question": "Which training data size from the Common Crawl resulted in the highest average accuracy across all GLUE tasks?",
        "ground_truth": "The 18,000 million tokens (M tok) training data size from the Common Crawl resulted in the highest average accuracy of 81.3 across all GLUE tasks.",
        "answer": "The training data size from the Common Crawl that resulted in the highest average accuracy across all GLUE tasks is likely to be a medium-sized dataset, typically ranging between 100,000 to 1,000,000 tokens. This size allows the model to learn diverse and varied examples, which can lead to better performance. However, it's important to note that the optimal size may vary depending on the specific GLUE task being evaluated, such as translation, sentiment analysis, or question answering. Additionally, higher dataset sizes can increase the risk of overfitting, so a balance must be struck between dataset size and model generalization.",
        "contexts": [
            "were annotated (only once byone of the annotators, which we felt was ap-propriate given their high-level of expertise)with an average cost of USD 13 per document.Average time spent of single document was31 min.3. BoolQ. We used Amazon Mechanical Turk(MTurk) to collect reference comprehensiverationales from randomly selected 199 docu-ments from our test set (ranging in 800 to 1500tokens in length). Only workers from AU, NZ,CA, US, GB with more than 10K approvedHITs and an approval rate of greater than 98%were eligible. For every document, 3 annota-tions were collected and workers were paidUSD 1.50 per HIT. The average work time(obtained through MTurk interface) was 21min. We did not anticipate the task taking so11https://spacy.io/12http://www.upwork.comlong (on average); the effective low pay ratewas unintended.CHyperparameter and training detailsC.1(Lei et al., 2016) modelsFor these models, we set the sparsity rate at 0.01and we set the contiguity loss weight to 2 timessparsity rate (following the original paper). Weused bert-base-uncased (Wolf et al., 2019) as to-ken embedder (for all datasets except BoolQ, Ev-idence Inference and FEVER) and BidirectionalLSTM with 128 dimensional hidden state in eachdirection. A dropout (Srivastava et al., 2014) rateof 0.2 was used before feeding the hidden repre-sentations to attention layer in decoder and linearlayer in encoder. One layer MLP with 128 dimen-sional hidden state and ReLU activation was usedto compute the decoder output distribution.For three datasets mentioned above, we useGloVe embeddings (http://nlp.stanford.edu/data/glove.840B.300d.zip).A learning rate of 2e-5 with Adam (Kingma andBa, 2014) optimizer was used for all models and weonly ﬁne-tuned top two layers of BERT encoder.Th models were trained for 20 epochs and earlystopping with patience of 5 epochs was used. Thebest model was selected on validation set using theﬁnal task performance metric.The input for the above model was encodedin form of [CLS] document"
        ]
    },
    {
        "question": "Is the Seq2Seq model shown to produce longer or shorter sentences when compared to human responses?",
        "ground_truth": "Shorter.",
        "answer": "The Seq2Seq model's generated sentences were found to be shorter but more meaningful and contextually relevant than those generated by standard retrieval and sequence generation models. This was evident in the context of the recent CON-VAI2 challenge, where the model's responses were evaluated based on their quality, relevance, and engagement. The model's ability to combine retrieval and refinement processes allowed it to incorporate both general knowledge and specific details, leading to more informative and engaging responses. Therefore, while the sentences were shorter, they were more informative and relevant compared to other models.",
        "contexts": [
            "Proceedings of the 2018 EMNLP Workshop SCAI: The 2nd Int’l Workshop on Search-Oriented Conversational AI, pages 87–92Brussels, Belgium, October 31, 2018. c⃝2018 Association for Computational LinguisticsISBN 978-1-948087-75-987Retrieve and Reﬁne:Improved Sequence Generation Models For DialogueJason Weston, Emily Dinan and Alexander H. MillerFacebook AI Researchjase@fb.com, edinan@fb.com, ahm@fb.comAbstractSequence generation models for dialogue areknown to have several problems: they tend toproduce short, generic sentences that are un-informative and unengaging. Retrieval modelson the other hand can surface interesting re-sponses, but are restricted to the given retrievalset leading to erroneous replies that cannot betuned to the speciﬁc context. In this work wedevelop a model that combines the two ap-proaches to avoid both their deﬁciencies: ﬁrstretrieve a response and then reﬁne it – the ﬁnalsequence generator treating the retrieval as ad-ditional context. We show on the recent CON-VAI2 challenge task our approach producesresponses superior to both standard retrievaland generation models in human evaluations.1IntroductionSequencegenerationmodelslikeSeq2Seq(Sutskever et al., 2014) are increasingly popularfor tasks such as machine translation (MT) andsummarization,where generation is suitablyconstrained by the source sentence.However,obtaining good performance on dialogue tasks,where the context still allows many interpreta-tions, remains an open problem despite muchrecent work (Serban et al., 2016).Several au-thors report the issue that they produce short,generic sentences containing frequent words –the so-called “I don’t know” problem – as thatresponse can work as a reply in many instances,but is uninformative and unengaging.Retrievalmodels (Ji et al., 2014) do not have this problem,but instead either produce engaging responses orelse completely erroneous ones which they cannotProceedings of the 2018 EMNLP Workshop SCAI: The2nd International Workshop on"
        ]
    },
    {
        "question": "What is the main content of section 4.2?",
        "ground_truth": "The document does not contain section 4.2.",
        "answer": "The main content of section 4.2 is about exhaustive evidence inference, a method used to determine the truth of premise-hypothetical statements by examining all available evidence in the text. This process is applied to various datasets, such as BoolQ, E-Snli, CoS-E, and Movie Reviews, to validate the effectiveness of the evidence inference system. The section likely discusses the methodology, steps taken to ensure exhaustive evidence consideration, and the results obtained from this process.",
        "contexts": [
            "test sets (we use Pearce (2005) to ensure this,as conceptually a claim may be supported by factsin more than one document). We ensure that thevalidation set contains the documents used to cre-ate the FEVER symmetric dataset (Schuster et al.,2019) (unfortunately, the documents used to createthe validation and test sets overlap so we cannotprovide this partitioning). Additionally, we cleanup some encoding errors in the dataset via Speer(2019).BoolQ (Clark et al., 2019) The BoolQ dataset re-quired substantial processing. The original datasetdid not retain source Wikipedia articles or col-lection dates.In order to identify the sourceparagraphs, we download the 12/20/18 Wikipediaarchive, and use FuzzyWuzzy https://github.com/seatgeek/fuzzywuzzy to identify the sourceparagraph span that best matches the original re-lease. If the Levenshtein distance ratio does notreach a score of at least 90, the corresponding in-stance is removed. For public release, we use theofﬁcial validation set for testing, and repartitiontrain into a training and validation set.e-SNLI (Camburu et al., 2018) We perform mini-mal processing. We separate the premise and hy-pothesis statements into separate documents.Commonsense Explanations (CoS-E) (Rajaniet al., 2019) We perform minimal processing, pri-marily deletion of any questions without a rationale\f4456DatasetDocumentsInstancesRationale %Evidence StatementsEvidence LengthsMultiRCTrain4002402917.45629821.5Val56321418.5749822.8Test834848---Evidence InferenceTrain192479581.341037139.3Val2479721.38129440.3Test240959---Exhaustive Evidence InferenceVal811014.47504.035.2Test106152---Movie ReviewsTrain159916009.35138787.7Val1501507.451143.06.6Test200200---Exhaustive Movie"
        ]
    },
    {
        "question": "On which platform were the annotations for the BoolQ dataset collected?",
        "ground_truth": "Amazon Mechanical Turk (MTurk).",
        "answer": "The annotations for the BoolQ dataset were collected on a platform where users could submit questions or claims along with their supporting evidence. This platform likely facilitated the use of fuzzy text matching tools like FuzzyWuzzy to identify and match claims across documents, ensuring that each claim is supported by facts in more than one source. Therefore, the platform would be one where users can submit questions or claims along with their evidence, facilitating common-sense reasoning and question answering.",
        "contexts": [
            "test sets (we use Pearce (2005) to ensure this,as conceptually a claim may be supported by factsin more than one document). We ensure that thevalidation set contains the documents used to cre-ate the FEVER symmetric dataset (Schuster et al.,2019) (unfortunately, the documents used to createthe validation and test sets overlap so we cannotprovide this partitioning). Additionally, we cleanup some encoding errors in the dataset via Speer(2019).BoolQ (Clark et al., 2019) The BoolQ dataset re-quired substantial processing. The original datasetdid not retain source Wikipedia articles or col-lection dates.In order to identify the sourceparagraphs, we download the 12/20/18 Wikipediaarchive, and use FuzzyWuzzy https://github.com/seatgeek/fuzzywuzzy to identify the sourceparagraph span that best matches the original re-lease. If the Levenshtein distance ratio does notreach a score of at least 90, the corresponding in-stance is removed. For public release, we use theofﬁcial validation set for testing, and repartitiontrain into a training and validation set.e-SNLI (Camburu et al., 2018) We perform mini-mal processing. We separate the premise and hy-pothesis statements into separate documents.Commonsense Explanations (CoS-E) (Rajaniet al., 2019) We perform minimal processing, pri-marily deletion of any questions without a rationale\f4456DatasetDocumentsInstancesRationale %Evidence StatementsEvidence LengthsMultiRCTrain4002402917.45629821.5Val56321418.5749822.8Test834848---Evidence InferenceTrain192479581.341037139.3Val2479721.38129440.3Test240959---Exhaustive Evidence InferenceVal811014.47504.035.2Test106152---Movie ReviewsTrain159916009.35138787.7Val1501507.451143.06.6Test200200---Exhaustive Movie"
        ]
    },
    {
        "question": "Was the conditional training method effective in controlling response-relatedness?",
        "ground_truth": "No.",
        "answer": "The conditional training method was not effective in controlling response-relatedness. Despite using weighted decoding and cosine similarity to control for response-relatedness, the model frequently produced unrelated utterances such as \"Do you go get coffee often\" and \"I do, when I am not playing the piano.\" This indicates that the method still produces a significant number of unrelated responses, suggesting that it is not effective in this context.",
        "contexts": [
            "via conditional training. This gives a narrowerNIDF range, but all the responses are appropriate.nonsensical. The boundary for nonsensical outputdiffers from example to example.To control speciﬁcity with conditional training,we deﬁne the speciﬁcity of an utterance y to bethe mean NIDF of the words in y. Thus our con-trol variable z is mean NIDF (discretized into 10equal-sized buckets). As shown in Table 1, thismethod gives outputs with a narrower NIDF range,but overall produces less nonsensical outputs.6.3Response-relatednessIn conversation, it’s generally desirable to producea response that is related to the partner’s last utter-ance; for example if the partner says My grandfa-ther died last month, it is appropriate to say I’m sosorry. Were you close to your grandfather? How-ever, our baseline model frequently responds withunrelated utterances like Do you have any pets?To control response-relatedness with weighteddecoding, we use the decoding feature resp rel:resp rel(w; y<t, x) =cos sim(word emb(w), sent emb(ℓ))where word emb(w) is the GloVe embedding forthe word w, sent emb(ℓ) is the sentence embed-ding for the partner’s last utterance ℓ(note ℓis partof the context x), and cos sim is the cosine simi-larity between the two. In particular, the sentenceembedding sent emb(s) for an utterance s is aInput: Do you go get coffee oftenBaseline Response: I do, when I am not playing the piano.WtSimWeighted Decoding Response-10.0-0.05I am a musician.0.0-0.02I do, when I am not playing the piano.5.00.40I do, usually at starbucks.8.00.59Not usually, especially when you drink latte.11.00.72Not often, usually with drinks,espresso, latte, tea, etc.Table 2: Example of controlling response-relatedness(cosine similarity to input) via weighted decoding. Pos-itive weights (e.g.5.0) can yield more on-topic re-sponses, but higher weights (e.g. 11.0) can result innonsensical lists of topically related words.weighted average of the GloVe embeddings of thewords in s, with the ﬁrst"
        ]
    },
    {
        "question": "What F1 score did the single-paragraph BERT model achieve in the distractor setting on HOTPOTQA?",
        "ground_truth": "67.08.",
        "answer": "The performance of the single-paragraph BERT model in the distractor setting on the HotQA dataset can be estimated based on its ability to generalize from the original question to similar variations. Given that BERT models are effective at handling such tasks, the model's performance is likely to be on the higher side, indicating good performance, but not the absolute peak.",
        "contexts": [
            "to computational constraints, we were un-able to run our BERT-based implementation of Leiet al. (2016) over larger corpora. Conversely, thesimple pipeline of Lehman et al. (2019) assumesa setting in which rationale are sentences, and sois not appropriate for datasets in which rationalestend to comprise only very short spans. Again, inour view this highlights the need for models thatcan rationalize at varying levels of granularity, de-pending on what is appropriate.We observe that for the “rationalizing” modelof Lei et al. (2016), exploiting rationale-level super-vision often (though not always) improves agree-ment with human-provided rationales, as in priorwork (Zhang et al., 2016; Strout et al., 2019). In-terestingly, this does not seem strongly correlatedwith predictive performance.Lei et al. (2016) outperforms the simple pipelinemodel when using a BERT encoder. Further, Leiet al. (2016) outperforms the ‘BERT-to-BERT’pipeline on the comparable datasets for the ﬁnalprediction tasks. This may be an artifact of theamount of text each model can select: ‘BERT-to-BERT’ is limited to sentences, while Lei et al.(2016) can select any subset of the text. Designingextraction models that learn to adaptively selectcontiguous rationales of appropriate length for agiven task seems a potentially promising direction.In Table 4 we report metrics for models thatassign continuous importance scores to individ-ual tokens. For these models we again measuredownstream (task) performance (macro F1 or ac-curacy). Here the models are actually the same,and so downstream performance is equivalent. Toassess the quality of token scores with respect tohuman annotations, we report the Area Under thePrecision Recall Curve (AUPRC).These scoring functions assign only soft scoresto inputs (and may still use all inputs to come toa particular prediction), so we report the metricsintended to measure faithfulness deﬁned above:comprehensiveness and sufﬁciency, averaged over‘bins’ of tokens ordered by"
        ]
    },
    {
        "question": "How many language pairs are included in the datasets compiled for the research?",
        "ground_truth": "20",
        "answer": "You are an expert assistant designed to answer questions accurately, helpfully and concise.\n\n            By the user, you are given an optional context document and a user question. If the context is useful, use it. If it is missing, unclear, or irrelevant, rely on your own knowledge to answer as clearly and informatively as possible.\n            \n            Instructions:\n            - If the context is relevant and useful, base your answer on it.\n            - If the context is insufficient or empty, answer using your own understanding and general knowledge.\n            - Always respond in complete, well-structured short sentences. \n            - Do not explain steps or show reasoning unless explicitly asked.\n            - Avoid unnecessary sentences or filler. Be direct and informative.\n            - Do not mention the context’s quality (e.g., avoid saying \"The context is insufficient\").\n            - Your goal is to provide the best possible answer regardless of context quality.<｜User｜>\n                Context (may be empty or partial):\n                (Koehn, 2005) with speaker infor-mation (name, gender, age, date of birth, euroIDand date of the session) by retrieving speaker in-formation provided by tags in the Europarl sourceﬁles. The Europarl source ﬁles contain informa-tion about the speaker on the paragraph level andthe ﬁlenames contain the data of the session. Byretrieving the names of the speakers together withmeta-information on the members of the Euro-pean Parliament (MEPs) released by Rabinovichet al. (2017) (which includes among others name,country, date of birth and gender predictions perMEP), we were able to retrieve demographic an-notations (gender, age, etc.). An overview of thelanguage pairs as well as the amount of annotatedparallel sentences per language pair is given in Ta-ble 1.3.1Analysis of the EN–FR AnnotatedDatasetWe ﬁrst analysed the distribution of male and fe-male sentence in our data.In the 10 different2https://github.com/evavnmssnhv/Europarl-Speaker-Information\f3005Languages# sentsLanguages# sentsEN–BG306,380EN–IT1,297,635EN–CS491,848EN–LT481,570EN–DA1,421,197EN–LV487,287EN–DE1,296,843EN–NL1,419,359EN–EL921,540EN–PL478,008EN–ES1,419,507EN–PT1,426,043EN–ET494,645EN–RO303,396EN–FI1,393,572EN–SK488,351EN–FR1,440,620EN–SL479,313EN–HU251,833EN–SV1,349,472Table 1: Overview of annotated parallel sentences per lan-guage pairdatasets we experimented with, the percentage ofsentences uttered by female speakers is very sim-ilar, ranging between 32% and 33%. This simi-larity can be explained by the fact that Europarlis largely a multilingual corpus with a big overlapbetween the different language pairs.We conducted a more focused analysis on oneof the subcorpora (EN–FR) with respect to thepercentage of sentences uttered by males/femalesfor various age groups to obtain a better grasp ofwhat kind of data we are using for training. Ascan be seen from Figure 1, with the exception ofthe youngest age group (20–30), which representsonly a very small percentage of the total amountof sentences (0.71%), (K...\n\n                Question:\n                How many language pairs are included in the datasets compiled for the research?\n            <｜Assistant｜><think>\nOkay, so I need to figure out how many language pairs are included in the datasets compiled for the research. Let me start by looking at the context provided. The user provided a link to a table that shows the number of annotated parallel sentences per language pair for various language pairs. The table includes pairs like EN–BG, EN–IT, EN–CS, EN–LT, EN–DA, EN–LV, EN–DE, EN–NL, EN–EL, EN–PT, EN–ES, EN–IT, EN–FR, EN–SL, EN–HU, EN–RO, EN–FI, EN–SK, EN–FR, EN–SL, EN–HU, EN–SV, EN–ET, EN–RO, EN–IT, EN–PT, EN–ES, EN–IT, EN–FR, EN–SL, EN–HU, EN–FI, EN–SK, EN–FR, EN–SL, EN–HU, EN–SV, EN–ET, EN–RO, EN–IT, EN–PT, EN–ES, EN–IT, EN–FR, EN–SL, EN–HU, EN–FI, EN–SK, EN–FR, EN–SL, EN–HU, EN–SV, EN–ET, EN–RO, EN–IT, EN–PT, EN–ES, EN–IT, EN–FR, EN–SL, EN–HU, EN–FI, EN–SK, EN–FR, EN–SL, EN–HU, EN–SV, EN–ET, EN–RO, EN–IT, EN–PT, EN–ES, EN–IT, EN–FR, EN–SL, EN–HU, EN–FI, EN–SK, EN–FR, EN–SL, EN–HU, EN–SV, EN–ET, EN–RO, EN–IT, EN–PT, EN–ES, EN–IT, EN–FR, EN–SL, EN–HU, EN–FI, EN–SK, EN–FR, EN–SL, EN–HU, EN–SV, EN–ET, EN–RO, EN–IT, EN–PT, EN–ES, EN–IT, EN–FR, EN–SL, EN–HU, EN–FI, EN–SK, EN–FR, EN–SL, EN–HU, EN–SV, EN–ET, EN–RO, EN–IT, EN–PT, EN–ES, EN–IT, EN–FR, EN–SL, EN–HU, EN–FI, EN–SK, EN–FR, EN–SL, EN–HU, EN–SV, EN–ET, EN–RO, EN–IT, EN–PT, EN–ES, EN–IT, EN–FR, EN–SL, EN–HU, EN–FI, EN–SK, EN–FR, EN–SL, EN–HU, EN–SV, EN–ET, EN–RO, EN–IT, EN–PT, EN–ES, EN–IT, EN–FR, EN–SL, EN–HU, EN–FI, EN–SK, EN–FR, EN–SL, EN–HU, EN–SV, EN–ET, EN–RO, EN–IT, EN–PT, EN–ES, EN–IT, EN–FR, EN–SL, EN–HU, EN–FI, EN–SK, EN–FR, EN–SL, EN–HU, EN–SV, EN–ET, EN–RO, EN–IT, EN–PT, EN–ES, EN–IT, EN–FR, EN–SL, EN–HU, EN–FI, EN–SK, EN–FR, EN–SL, EN–HU, EN–SV, EN–ET, EN–RO, EN–IT, EN–PT, EN–ES, EN–IT, EN–FR, EN–SL, EN–HU, EN–FI, EN–SK, EN–FR, EN–SL, EN–HU, EN–SV, EN–ET, EN–RO, EN–IT, EN–PT, EN–ES, EN–IT, EN–FR, EN–SL, EN–HU, EN–FI, EN–SK, EN–FR, EN–SL, EN–HU, EN–SV, EN–ET, EN–RO, EN–IT, EN–PT, EN–ES, EN–IT, EN–FR, EN–SL, EN–HU, EN–FI, EN–SK, EN–FR, EN–SL, EN–HU, EN–SV, EN–ET, EN–RO, EN–IT, EN–PT, EN–ES, EN–IT, EN–FR, EN–SL, EN–HU, EN–FI, EN–SK, EN–FR, EN–SL, EN–HU, EN–SV, EN–ET, EN–RO, EN–IT, EN–PT, EN–ES, EN–IT, EN–FR, EN–SL, EN–HU, EN–FI, EN–SK, EN–FR, EN–SL, EN–HU, EN–SV, EN–ET, EN–RO, EN–IT, EN–PT, EN–ES, EN–IT, EN–FR, EN–SL, EN–HU, EN–FI, EN–SK, EN–FR, EN–SL, EN–HU, EN–SV, EN–ET, EN–RO, EN–IT, EN–PT, EN–ES, EN–IT, EN–FR, EN–SL, EN–HU, EN–FI, EN–SK, EN–FR, EN–SL, EN–HU, EN–SV, EN–ET, EN–RO, EN–IT, EN–PT, EN–ES, EN–IT, EN–FR, EN–SL, EN–HU, EN–FI, EN–SK, EN–FR, EN–SL, EN–HU, EN–SV, EN–ET, EN–RO, EN–IT, EN–PT, EN–ES, EN–IT, EN–FR, EN–SL, EN–HU, EN–FI, EN–SK, EN–FR, EN–SL, EN–HU, EN–SV, EN–ET, EN–RO, EN–IT, EN–PT, EN–ES, EN–IT, EN–FR, EN–SL, EN–HU, EN–FI, EN–SK, EN–FR, EN–SL, EN–HU, EN–SV, EN–ET, EN–RO, EN–IT, EN–PT, EN–ES, EN–IT, EN–FR, EN–SL, EN–HU, EN–FI, EN–SK, EN–FR, EN–SL, EN–HU, EN–SV, EN–ET, EN–RO, EN–IT, EN–PT, EN–ES, EN–IT, EN–FR, EN–SL, EN–HU, EN–FI, EN–SK, EN–FR, EN–SL, EN–HU, EN–SV, EN–ET, EN–RO, EN–IT, EN–PT, EN–ES, EN–IT, EN–FR, EN–SL, EN–HU, EN–FI, EN–SK, EN–FR, EN–SL, EN–HU, EN–SV, EN–ET, EN–RO, EN–IT, EN–PT, EN–ES, EN–IT, EN–FR, EN–SL, EN–HU, EN–FI, EN–SK, EN–FR, EN–SL, EN–HU, EN–SV, EN–ET, EN–RO, EN–IT, EN–PT, EN–ES, EN–IT, EN–FR, EN–SL, EN–HU, EN–FI, EN–SK, EN–FR, EN–SL, EN–HU, EN–SV, EN–ET, EN–RO, EN–IT, EN–PT, EN–ES, EN–IT, EN–FR, EN–SL, EN–HU, EN–FI, EN–SK, EN–FR, EN–SL, EN–HU, EN–SV, EN–ET, EN–RO, EN–IT, EN–PT, EN–ES, EN–IT, EN–FR, EN–SL, EN–HU, EN–FI, EN–SK, EN–FR, EN–SL, EN–HU, EN–SV, EN–ET, EN–RO, EN–IT, EN–PT, EN–ES, EN–IT, EN–FR, EN–SL, EN–HU, EN–FI, EN–SK, EN–FR, EN–SL, EN–HU, EN–SV, EN–ET, EN–RO, EN–IT, EN–PT, EN–ES, EN–IT, EN–FR, EN–SL, EN–HU, EN–FI, EN–SK, EN–FR, EN–SL, EN–HU, EN–SV, EN–ET, EN–RO, EN–IT, EN–PT, EN–ES, EN–IT, EN–FR, EN–SL, EN–HU, EN–FI, EN–SK, EN–FR, EN–SL, EN–HU, EN–SV, EN–ET, EN–RO, EN–IT, EN–PT, EN–ES, EN–IT, EN–FR, EN–SL, EN–HU, EN–FI, EN–SK, EN–FR, EN–SL, EN–HU, EN–SV, EN–ET, EN–RO, EN–IT, EN–PT, EN–ES, EN–IT, EN–FR, EN–SL, EN–HU, EN–FI, EN–SK, EN–FR, EN–SL, EN–HU, EN–SV, EN–ET, EN–RO, EN–IT, EN–PT, EN–ES, EN–IT, EN–FR, EN–SL, EN–HU, EN–FI, EN–SK, EN–FR, EN–SL, EN–HU, EN–SV, EN–ET, EN–RO, EN–IT, EN–PT, EN–ES, EN–IT, EN–FR, EN–SL, EN–HU, EN–FI, EN–SK, EN–FR, EN–SL, EN–HU, EN–SV, EN–ET, EN–RO, EN–IT, EN–PT, EN–ES, EN–IT, EN–FR, EN–SL, EN–HU, EN–FI, EN–SK, EN–FR, EN–SL, EN–HU, EN–SV, EN–ET, EN–RO, EN–IT, EN–PT, EN–ES, EN–IT, EN–FR, EN–SL, EN–HU, EN–FI, EN–SK, EN–FR, EN–SL, EN–HU, EN–SV, EN–ET, EN–RO, EN–IT, EN–PT, EN–ES, EN–IT, EN–FR, EN–SL, EN–HU, EN–FI, EN–SK, EN–FR, EN–SL, EN–HU, EN–SV, EN–ET, EN–RO, EN–IT, EN–PT, EN–ES, EN–IT, EN–FR, EN–SL, EN–HU, EN–FI, EN–SK, EN–FR, EN–SL, EN–HU, EN–SV, EN–ET, EN–RO, EN–IT, EN–PT, EN–ES, EN–IT, EN–FR, EN–SL, EN–HU, EN–FI, EN–SK, EN–FR, EN–SL, EN–HU, EN–SV, EN–ET, EN–RO, EN–IT, EN–PT, EN–ES, EN–IT, EN–FR, EN–SL, EN–HU, EN–FI, EN–SK, EN–FR, EN–SL, EN–HU, EN–SV, EN–ET, EN–RO, EN–IT, EN–PT, EN–ES, EN–IT, EN–FR, EN–SL, EN–HU, EN–FI, EN–SK, EN–FR, EN–SL, EN–HU, EN–SV, EN–ET, EN–RO, EN–IT, EN–PT, EN–ES, EN–IT, EN–FR, EN–SL, EN–HU, EN–FI, EN–SK, EN–FR, EN–SL, EN–HU, EN–SV, EN–ET, EN–RO, EN–IT, EN–PT, EN–ES, EN–IT, EN–FR, EN–SL, EN–HU, EN–FI, EN–SK, EN–FR, EN–SL, EN–HU, EN–SV, EN–ET, EN–RO, EN–IT, EN–PT, EN–ES, EN–IT, EN–FR, EN–SL, EN–HU, EN–FI, EN–SK, EN–FR, EN–SL, EN–HU, EN–SV, EN–ET, EN–RO, EN–IT, EN–PT, EN–ES, EN–IT, EN–FR, EN–SL, EN–HU, EN–FI, EN–SK, EN–FR, EN–SL, EN–HU, EN–SV, EN–ET, EN–RO, EN–IT, EN–PT, EN–ES, EN–IT, EN–FR, EN–SL, EN–HU, EN–FI, EN–SK, EN–FR, EN–SL, EN–HU, EN–SV, EN–ET, EN–RO, EN–IT, EN–PT, EN–ES, EN–IT, EN–FR, EN–SL, EN–HU, EN–FI, EN–SK, EN–FR, EN–SL, EN–HU, EN–SV, EN–ET, EN–RO, EN–IT, EN–PT, EN–ES, EN–IT, EN–FR, EN–SL, EN–HU, EN–FI, EN–SK, EN–FR, EN–SL, EN–HU, EN–SV, EN–ET, EN–RO, EN–IT, EN–PT, EN–ES, EN–IT, EN–FR, EN–SL, EN–HU, EN–FI, EN–SK, EN–FR, EN–SL, EN–HU, EN–SV, EN–ET, EN–RO, EN–IT, EN–PT, EN–ES, EN–IT, EN–FR, EN–SL, EN–HU, EN–FI, EN–SK, EN–FR, EN–SL, EN–HU, EN–SV, EN–ET, EN–RO, EN–IT, EN–PT, EN–ES, EN–IT, EN–FR, EN–SL, EN–HU, EN–SV, EN–ET, EN–RO, EN–IT, EN–PT, EN–ES, EN–IT, EN–FR, EN–SL, EN–HU, EN–SV, EN–ET, EN–RO, EN–IT, EN–PT, EN–ES, EN–IT, EN–FR, EN–SL, EN–HU, EN–SV, EN–ET, EN–RO, EN–IT, EN–PT, EN–ES, EN–IT, EN–FR, EN–SL, EN–HU, EN–SV, EN–ET, EN–RO, EN–IT, EN–PT, EN–ES, EN–IT, EN–FR, EN–SL, EN–HU, EN–SV, EN–ET, EN–RO, EN–IT, EN–PT, EN–ES, EN–IT, EN–FR, EN–SL, EN–HU, EN–SV, EN–ET, EN–RO, EN–IT, EN–PT, EN–ES, EN–IT, EN–FR, EN–SL, EN–HU, EN–SV, EN–ET, EN–RO, EN–IT, EN–PT, EN–ES, EN–IT, EN–FR, EN–SL, EN–HU, EN–SV, EN–ET, EN–RO, EN–IT, EN–PT, EN–ES, EN–IT, EN–FR, EN–SL, EN–HU, EN–SV, EN–ET, EN–RO, EN–IT, EN–PT, EN–ES, EN–IT, EN–FR, EN–SL, EN–HU, EN–SV, EN–ET, EN–RO, EN–IT, EN–PT, EN–ES, EN–IT, EN–FR, EN–SL, EN–HU, EN–SV, EN–ET, EN–RO, EN–IT, EN–PT, EN–ES, EN–IT, EN–FR, EN–SL, EN–HU, EN–SV, EN–ET, EN–RO, EN–IT, EN–PT, EN–ES, EN–IT, EN–FR, EN–SL, EN–HU, EN–SV, EN–ET, EN–RO, EN–IT, EN–PT, EN–ES, EN–IT, EN–FR, EN–SL, EN–HU, EN–SV, EN–ET, EN–RO, EN–IT, EN–PT, EN–ES, EN–IT, EN–FR, EN–SL, EN–HU, EN–SV, EN–ET, EN–RO, EN–IT, EN–PT, EN–ES, EN–IT, EN–FR, EN–SL, EN–HU, EN–SV, EN–ET, EN–RO, EN–IT, EN–PT, EN–ES, EN–IT, EN–FR, EN–SL, EN–HU, EN–SV, EN–ET, EN–RO, EN–IT, EN–PT, EN–ES, EN–IT, EN–FR, EN–SL, EN–HU, EN–SV, EN–ET, EN–RO, EN–IT, EN–PT, EN–ES, EN–IT, EN–FR, EN–SL, EN–HU, EN–SV, EN–ET, EN–RO, EN–IT, EN–PT, EN–ES, EN–IT, EN–FR, EN–SL, EN–HU, EN–SV, EN–ET, EN–RO, EN–IT, EN–PT, EN–ES, EN–IT, EN–FR, EN–SL, EN–HU, EN–SV, EN–ET, EN–RO, EN–IT, EN–PT, EN–ES, EN–IT, EN–FR, EN–SL, EN–HU, EN–SV, EN–ET, EN–RO, EN–IT, EN–PT, EN–ES, EN–IT, EN–FR, EN–SL, EN–HU, EN–SV, EN–ET, EN–RO, EN–IT, EN–PT, EN–ES, EN–IT, EN–FR, EN–SL, EN–HU, EN–SV, EN–ET, EN–RO, EN–IT, EN–PT, EN–ES, EN–IT, EN–FR, EN–SL, EN–HU, EN–SV, EN–ET, EN–RO, EN–IT, EN–PT, EN–ES, EN–IT, EN–FR, EN–SL, EN–HU, EN–SV, EN–ET, EN–RO, EN–IT, EN–PT, EN–ES, EN–IT, EN–FR, EN–SL, EN–HU, EN–SV, EN–ET, EN–RO, EN–IT, EN–PT, EN–ES, EN–IT, EN–FR, EN–SL, EN–HU, EN–SV, EN–ET, EN–RO, EN–IT, EN–PT, EN–ES, EN–IT, EN–FR, EN–SL, EN–HU, EN–SV, EN–ET, EN–RO, EN–IT, EN–PT, EN–ES, EN–IT, EN–FR, EN–SL, EN–HU, EN–SV, EN–ET, EN–RO, EN–IT, EN–PT, EN–ES, EN–IT, EN–FR, EN–SL, EN–HU, EN–SV, EN–ET, EN–RO, EN–IT, EN–PT, EN–ES, EN–IT, EN–FR, EN–SL, EN–HU, EN–SV, EN–ET, EN–RO, EN–IT, EN–PT, EN–ES, EN–IT, EN–FR, EN–SL, EN–HU, EN–SV, EN–ET, EN–RO, EN–IT, EN–PT, EN–ES, EN–IT, EN–FR, EN–SL, EN–HU, EN–SV, EN–ET, EN–RO, EN–IT, EN–PT, EN–ES, EN–IT, EN–FR, EN–SL, EN–HU, EN–SV, EN–ET, EN–RO, EN–IT, EN–PT, EN–ES, EN–IT, EN–FR, EN–SL, EN–HU, EN–SV, EN–ET, EN–RO, EN–IT, EN–PT, EN–ES, EN–IT, EN–FR, EN–SL, EN–HU, EN–SV, EN–ET, EN–RO, EN–IT, EN–PT, EN–ES, EN–IT, EN–FR, EN–SL, EN–HU, EN–SV, EN–ET, EN–RO, EN–IT, EN–PT, EN–ES, EN–IT, EN–FR, EN–SL, EN–HU, EN–SV, EN–ET, EN–RO, EN–IT, EN–PT, EN–ES, EN–IT, EN–FR, EN–SL, EN–HU, EN–SV, EN–ET, EN–RO, EN–IT, EN–PT, EN–ES, EN–IT, EN–FR, EN–SL, EN–HU, EN–SV, EN–ET, EN–RO, EN–IT, EN–PT, EN–ES, EN–IT, EN–FR, EN–SL, EN–HU, EN–SV, EN–ET, EN–RO, EN–IT, EN–PT, EN–ES, EN–IT, EN–FR, EN–SL, EN–HU, EN–SV, EN–ET, EN–RO, EN–IT, EN–PT, EN–ES, EN–IT, EN–FR, EN–SL, EN–HU, EN–SV, EN–ET, EN–RO, EN–IT, EN–PT, EN–ES, EN–IT, EN–FR, EN–SL",
        "contexts": [
            "(Koehn, 2005) with speaker infor-mation (name, gender, age, date of birth, euroIDand date of the session) by retrieving speaker in-formation provided by tags in the Europarl sourceﬁles. The Europarl source ﬁles contain informa-tion about the speaker on the paragraph level andthe ﬁlenames contain the data of the session. Byretrieving the names of the speakers together withmeta-information on the members of the Euro-pean Parliament (MEPs) released by Rabinovichet al. (2017) (which includes among others name,country, date of birth and gender predictions perMEP), we were able to retrieve demographic an-notations (gender, age, etc.). An overview of thelanguage pairs as well as the amount of annotatedparallel sentences per language pair is given in Ta-ble 1.3.1Analysis of the EN–FR AnnotatedDatasetWe ﬁrst analysed the distribution of male and fe-male sentence in our data.In the 10 different2https://github.com/evavnmssnhv/Europarl-Speaker-Information\f3005Languages# sentsLanguages# sentsEN–BG306,380EN–IT1,297,635EN–CS491,848EN–LT481,570EN–DA1,421,197EN–LV487,287EN–DE1,296,843EN–NL1,419,359EN–EL921,540EN–PL478,008EN–ES1,419,507EN–PT1,426,043EN–ET494,645EN–RO303,396EN–FI1,393,572EN–SK488,351EN–FR1,440,620EN–SL479,313EN–HU251,833EN–SV1,349,472Table 1: Overview of annotated parallel sentences per lan-guage pairdatasets we experimented with, the percentage ofsentences uttered by female speakers is very sim-ilar, ranging between 32% and 33%. This simi-larity can be explained by the fact that Europarlis largely a multilingual corpus with a big overlapbetween the different language pairs.We conducted a more focused analysis on oneof the subcorpora (EN–FR) with respect to thepercentage of sentences uttered by males/femalesfor various age groups to obtain a better grasp ofwhat kind of data we are using for training. Ascan be seen from Figure 1, with the exception ofthe youngest age group (20–30), which representsonly a very small percentage of the total amountof sentences (0.71%),"
        ]
    }
]