[
    {
        "question": "What is the top-1 accuracy of the Oracle KGLM on birthdate prediction?",
        "context": "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages 5962–5971Florence, Italy, July 28 - August 2, 2019. c⃝2019 Association for Computational Linguistics5962Barack’s Wife Hillary:Using Knowledge Graphs for Fact-Aware Language ModelingRobert L. Logan IV∗Nelson F. Liu†§Matthew E. Peters§Matt Gardner§Sameer Singh∗∗University of California, Irvine, CA, USA† University of Washington, Seattle, WA, USA§ Allen Institute for Artiﬁcial Intelligence, Seattle, WA, USA{rlogan, sameer}@uci.edu, {mattg, matthewp}@allenai.org, nﬂiu@cs.washington.eduAbstractModeling human language requires the abilityto not only generate ﬂuent text but also en-code factual knowledge. However, traditionallanguage models are only capable of remem-bering facts seen at training time, and oftenhave difﬁculty recalling them. To address this,we introduce the knowledge graph languagemodel (KGLM), a neural language model withmechanisms for selecting and copying factsfrom a knowledge graph that are relevant tothe context.These mechanisms enable themodel to render information it has never seenbefore, as well as generate out-of-vocabularytokens. We also introduce the Linked WikiText-2 dataset,1 a corpus of annotated text aligned tothe Wikidata knowledge graph whose contents(roughly) match the popular WikiText-2 bench-mark (Merity et al., 2017). In experiments, wedemonstrate that the KGLM achieves signiﬁ-cantly better performance than a strong base-line language model.We additionally com-pare different language models’ ability to com-plete sentences requiring factual knowledge,and show that the KGLM outperforms evenvery large language models in generating facts.1IntroductionFor language models to generate plausible sen-tences, they must be both syntactically coherent aswell as consistent with the world they describe. Al-though language models are quite skilled at generat-ing grammatical sentences, and previous work hasshown that language models also possess some de-gree of common-sense reasoning and basic knowl-edge (Vinyals and Le, 2015; Serban et al., 2016;Trinh and Le, 2019), their ability to generate fac-tually correct text is quite limited. The clearestlimitation of existing language models is that they,at best, can only memorize facts observed during1https://rloganiv.github.io/linked-wikitext-2[Super Mario Land] is a [1989] [side-scrolling][platform video game] developed and publishedby [Nintendo] as a [launch title] for their [GameBoy] [handheld game console].Date21 April 1989Q828322platform gameQ8093NintendoQ647249Super Mario LandQ186437Game BoyQ941818handheld game consoleQ2281714side-scrolling video gameQ1425505launch gamePublicationDategenrepublisherplatformmanufacturerinstance ofFigure 1:Linked WikiText-2 Example. A localizedknowledge graph containing facts that are (possibly)conveyed in the sentence above. The graph is built by it-eratively linking each detected entity to Wikidata, thenadding any relations to previously mentioned entities.Note that not all entities are connected, potentially dueto missing relations in Wikidata.training. For instance, when conditioned on the textat the top of Figure 1, an AWD-LSTM languagemodel (Merity et al., 2018) trained on Wikitext-2assigns higher probability to the word “PlaySta-tion” than “Game Boy”, even though this sentenceappears verbatim in the training data. This is notsurprising—existing models represent the distribu-tion over the entire vocabulary directly, whetherthey are common words, references to real worldentities, or factual information like dates and num-bers. As a result, language models are unable togenerate factually correct sentences, do not gen-eralize to rare/unseen entities, and often omit raretokens from the vocabulary (instead generating UN-KNOWN tokens).We introduce the knowledge graph languagemodel (KGLM), a neural language model withmechanisms for selecting and copying informationfrom an external knowledge graph. The KGLMmaintains a dynamically growing local knowledge\f5963graph, a subset of the knowledge graph that con-tains entities that have already been mentioned inthe text, and their related entities. When generatingentity tokens, the model either decides to rendera new entity that is absent from the local graph,thereby growing the local knowledge graph, or torender a fact from the local graph. When render-ing, the model combines the standard vocabularywith tokens available in the knowledge graph, thussupporting numbers, dates, and other rare tokens.Figure 1 illustrates how the KGLM works. Ini-tially, the graph is empty and the model uses theentity Super Mario Land to render the ﬁrst threetokens, thus adding it and its relations to the localknowledge graph. After generating the next two to-kens (“is”, “a”) using the standard language model,the model selects Super Mario Land as the parententity, Publication Date as the relation to render,and copies one of the tokens of the date entity asthe token (“1989” in this case).To facilitate research on knowledge graph-basedlanguage modeling, we collect the distantly su-pervised Linked WikiText-2 dataset. The underly-ing text closely matches WikiText-2 (Merity et al.,2017), a popular benchmark for language model-ing, allowing comparisons against existing mod-els. The tokens in the text are linked to entities inWikidata (Vrandeˇci´c and Krötzsch, 2014) using acombination of human-provided links and off-the-shelf linking and coreference models. We also userelations between these entities in Wikidata to con-struct plausible reasons for why an entity may havebeen mentioned: it could either be related to anentity that is already mentioned (including itself)or a brand new, unrelated entity for the document.We train and evaluate the KGLM on LinkedWikiText-2. When compared against AWD-LSTM,a recent and performant language model, KGLMobtains not only a lower overall perplexity, but alsoa substantially lower unknown-penalized perplex-ity (Ueberla, 1994; Ahn et al., 2016), a metric thatallows fair comparisons between models that accu-rately model rare tokens and ones that predict themto be unknown. We also compare factual com-pletion capabilities of these models, where theypredict the next word after a factual sentence (e.g.,“Barack is married to”) and show that KGLMis signiﬁcantly more accurate. Lastly, we show thatthe model is able to generate accurate facts for rareentities, and can be controlled via modiﬁcationsthe knowledge graph.2Knowledge Graph Language ModelIn this section we introduce a language model thatis conditioned on an external, structured knowledgesource, which it uses to generate factual text.2.1Problem Setup and NotationA language model deﬁnes a probability distributionover each token within a sequence, conditioned onthe sequence of tokens observed so far. We denotethe random variable representing the next token asxt and the sequence of the tokens before t as x<t,i.e. language models compute p(xt|x<t). RNN lan-guage models (Mikolov et al., 2010) parameterizethis distribution using a recurrent structure:p(xt|x<t) = softmax(Whht + b),ht = RNN(ht−1, xt−1).(1)We use LSTMs (Hochreiter and Schmidhuber,1997) as the recurrent module in this paper.A knowledge graph (KG) is a directed, labeledgraph consisting of entities E as nodes, with edgesdeﬁned over a set of relations R, i.e.KG ={(p, r, e) | p ∈E, r ∈R, e ∈E}, where p is a par-ent entity with relation r to another entity e. Prac-tical KGs have other aspects that make this for-mulation somewhat inexact: some relations are toliteral values, such as numbers and dates, factsmay be expressed as properties on relations, andentities have aliases as the set of strings that canrefer to the entity. We also deﬁne a local knowl-edge graph for a subset of entities E<t as KG<t ={(p, r, e) | p ∈E<t, r ∈R, e ∈E}, i.e.containsentities E<t and all facts they participate in.2.2Generative KG Language ModelThe primary goal of the knowledge graph lan-guage model (KGLM) is to enable a neural lan-guage model to generate entities and facts froma knowledge graph. To encourage the model togenerate facts that have appeared in the contextalready, KGLM will maintain a local knowledgegraph containing all facts involving entities thathave appeared in the context. As the model decidesto refer to entities that have not been referred toyet, it will grow the local knowledge graph withadditional entities and facts to reﬂect the new entity.Formally, we will compute p(xt, Et|x<t, E<t)where x<t is the sequence of observed tokens, E<tis the set of entities mentioned in x<t, and KG<t isthe local knowledge graph determined by E<t, asdescribed above. The generative process is:\f5964Super Mario Land is a 1989 side-scrolling platform video game developed and published by      AAA I nc.Sony I nc.. . .. . .Zzyzx,  CApl at f or m gameSuper  Mar i o Land. . .si de- scr ol l i ng gameSuper  Mar i o LandNi nt endoGame Boypl at f or m game1989PUBLI SHERGENREPLATFORMPUB. DATEathedog...companyKabushikiKoppaiNintendo...Relation toExisting EntityMention of a New EntityNot an Entity MentionDistribution over standard vocabulary and aliases of etDistribution over standard vocabularystandard vocabularyaliases of etSELFNintendopick from all entitiesparent from local entitiesFigure 2: KGLM Illustration. When trying to generate the token following “published by”, the model ﬁrst decidesthe type of the mention (tt) to be a related entity (darker indicates higher probability), followed by identifying theparent (pt), relation (rt), and entity to render (et) from the local knowledge graph as (Super Mario Land, Publisher,Nintendo). The ﬁnal distribution over the words includes the standard vocabulary along with aliases of Nintendo,and the model selects “Nintendo” as the token xt. Facts related to Nintendo will be added to the local graph.• Decide the type of xt, which we denote bytt: whether it is a reference to an entity inKG<t (related), a reference to an entity not inKG<t (new), or not an entity mention (∅).• If tt = new then choose the upcoming entity etfrom the set of all entities E.• If tt = related then:– Choose a parent entity pt from E<t.– Choose a factual relation rt to render,rt ∈{(p, r, e) ∈KG<t|p = pt}.– Choose et as one of the tail entities,et ∈{e|(pt, rt, e) ∈KG<t}.• If tt = ∅then et = ∅.• Generate xt conditioned on et, potentially copy-ing one of et’s aliases.• If et /∈E<t, then E<(t+1) ←E<t ∪{et},else E<(t+1) ←E<t.For the model to refer to an entity it has alreadymentioned, we introduce a Reﬂexive relation thatself-relates, i.e. p = e for (p, Reﬂexive, e).An illustration of this process and the variablesis provided in Figure 2, for generating a token inthe middle of the same sentence as in Figure 1.Amongst the three mention types (tt), the modelchooses a reference to existing entity, which re-quires picking a fact to render. As the parent entityof this fact (pt), the model picks Super Mario Land,and then follows the Publisher relation (rt) to se-lect Nintendo as the entity to render (et). Whenrendering Nintendo as a token xt, the model has anexpanded vocabulary available to it, containing thestandard vocabulary along with all word types inany of the aliases of et.Marginalizing out the KG There is a mismatchbetween our initial task requirement, p(xt|x<t),and the model we describe so far, which computesp(xt, Et|x<t, E<t). We will essentially marginal-ize out the local knowledge graph to compute theprobability of the tokens, i.e. p(x) = PE p(x, E).We will clarify this, along with describing the train-ing and the inference/decoding algorithms for thismodel and other details of the setup, in Section 4.2.3Parameterizing the DistributionsThe parametric distributions used in the generativeprocess above are deﬁned as follows. We beginby computing the hidden state ht using the for-mula in Eqn (1). We then split the vector intothree components: ht = [ht,x; ht,p; ht,r], whichare respectively used to predict words, parents, andrelations. The type of the token, tt, is computedusing a single-layer softmax over ht,x to predictone of {new, related, ∅}.Picking an Entity We also introduce pretrainedembeddings for all entities and relations in the\f5965knowledge graph, denoted by ve for entity e andvr for relation r. To select et from all entities incase tt = new, we use:p(et) = softmax(ve · (ht,p + ht,r))over all e ∈E. The reason we add ht,p and ht,r isto mimic the structure of TransE, which we use toobtain entity and relation embeddings. Details onTransE will be provided in Section 4. For mentionof a related entity, tt = related, we pick a parententity pt usingp(pt) = softmax(vp · ht,p)over all p ∈Et, then pick the relation rt usingp(rt) = softmax(vr · ht,r)over all r ∈{r|(pt, r, e) ∈KGt}. The combina-tion of pt and rt determine the entity et (whichmust satisfy (pt, rt, et) ∈KGt; if there are multi-ple options one is chosen at random).Rendering the Entity If et = ∅, i.e. there isno entity to render, we use the same distributionover the vocabulary as in Eqn (1) - a softmax usinght,x. If there is an entity to render, we constructthe distribution over the original vocabulary anda vocabulary containing all the tokens that appearin aliases of et. This distribution is conditionedon et in addition to xt. To compute the scoresover the original vocabulary, ht,x is replaced byh′t,x = Wproj[ht,x; vet] where Wproj is a learnedweight matrix that projects the concatenated vectorinto the same vector space as ht,x.To obtain probabilities for words in the aliasvocabulary, we use a copy mechanism Gu et al.(2016). The token sequences comprising each alias{aj} are embedded then encoded using an LSTMto form vectors aj. Copy scores are computed as:p(xt = aj) ∝exphσ\u0010\u0000h′t,x\u0001T Wcopy\u0011aji3Linked WikiText-2Modeling aside, one of the primary barriers to in-corporating factual knowledge into language mod-els is that training data is hard to obtain. Standardlanguage modeling corpora consist only of text,and thus are unable to describe which entities orfacts each token is referring to. In contrast, whilerelation extraction datasets link text to a knowledgegraph, the text is made up of disjoint sentences thatdo not provide sufﬁcient context to train a pow-erful language model. Our goals are much morealigned to the data-to-text task (Ahn et al., 2016;Lebret et al., 2016; Wiseman et al., 2017; Yanget al., 2017; Gardent et al., 2017; Ferreira et al.,2018), where a small table-sized KB is provided togenerate a short piece of text; we are interested inlanguage models that dynamically decide the factsto incorporate from the knowledge graph, guidedby the discourse.For these reasons we introduce the LinkedWikiText-2 dataset, consisting of (approximately)the same articles appearing in the WikiText-2 lan-guage modeling corpus, but linked to the Wiki-data (Vrandeˇci´c and Krötzsch, 2014) knowledgegraph. Because the text closely matches, mod-els trained on Linked WikiText-2 can be comparedto models trained on WikiText-2.Furthermore,because many of the facts in Wikidata are de-rived from Wikipedia articles, the knowledge graphhas a good coverage of facts expressed in thetext.The dataset is available for download at:https://rloganiv.github.io/linked-wikitext-2. Oursystem annotates one document at a time, and con-sists of entity linking, relation annotations, andpost-processing.The following paragraphs de-scribe each step in detail.Initial entity annotations We begin by identify-ing an initial set of entity mentions within the text.The primary source of these mentions is the human-provided links between Wikipedia articles. When-ever a span of text is linked to another Wikipediaarticle, we associate its corresponding Wikidataentity with the span. While article links provide alarge number of gold entity annotations, they are in-sufﬁcient for capturing all of the mentions in the ar-ticle since entities are only linked the ﬁrst time theyoccur. Accordingly, we use the neural-el (Guptaet al., 2017) entity linker to identify additional linksto Wikidata, and identify coreferences using Stan-ford CoreNLP2 to cover pronouns, nominals, andother tokens missed by the linker.Local knowledge graph The next step iterativelycreates a generative story for the entities using rela-tions in the knowledge graph as well as identiﬁesnew entities. To do this, we process the text tokenby token. Each time an entity is encountered, weadd all of the related entities in Wikidata as candi-2https://stanfordnlp.github.io/CoreNLP/\f5966Tokens xt Super Mario Land is a1989side - scrolling platform video game developedMention typettnew∅∅relatednewrelated∅Entity Mentioned etSML∅∅04-21-1989 SIDE_SCROLLPVG∅Relation rt∅∅∅pub date∅genre∅Parent Entity pt∅∅∅SML∅SML∅xt and published by Nintendo as a launch title for their GameBoyhandheld game console.tt∅∅∅related∅∅new∅∅relatedrelated∅et∅∅∅NIN∅∅LT∅∅GAME_BOYHGC∅rt∅∅∅pub∅∅∅∅∅R:manu / platforminstance of∅pt∅∅∅SML∅∅∅∅∅NIN / SMLGAME_BOY∅Table 1: Example Annotation of the sentence from Figure 1, including corresponding variables from Figure 2.Note that Game Boy has multiple parent and relation annotations, as the platform for Super Mario Land and asmanufactured by Nintendo. Wikidata identiﬁers are made human-readable (e.g., SML is Q647249) for clarity.dates for matching. If one of these related entitiesis seen later in the document, we identify the entityas a parent for the later entity. Since multiple re-lations may appear as explanations for each token,we allow a token to have multiple facts.Expanding the annotations Since there may beentities that were missed in the initial set, as wellas non-entity tokens of interest such as dates andquantities we further expand the entity annotationsusing string matching. For entities, we match theset of aliases provided in Wikidata. For dates, wecreate an exhaustive list of all of the possible waysof expressing the date (e.g. \"December 7, 1941\",\"7-12-1941\", \"1941\", ...). We perform a similarapproach for quantities, using the pint library inPython to handle the different ways of expressingunits (e.g. \"g\", \"gram\", ...). Since there are manyways to express a numerical quantity, we only ren-der the quantity at the level of precision suppliedby Wikidata, and do not perform unit conversions.Example Annotation An example annotation isprovided in Table 1 corresponding to the instance inFigure 1, along with the variables that correspondto the generative process of the knowledge graphlanguage model (KGLM). The entity mentioned formost tokens here are human-provided links, apartfrom “1989” that is linked to 04-21-1989 by thestring matching process. The annotations indicatewhich of the entities are new and related based onwhether they are reachable by entities linked so far,clearly making a mistake for side-scrolling gameand platform video game due to missing links inWikidata. Finally, multiple plausible reasons forGame Boy are included: it’s the platform for SuperMario Land and it is manufactured by Nintendo,even though only the former is more relevant here.TrainDevTestDocuments6006060Tokens2,019,195207,982236,062Vocab. Size33,558--Mention Tokens207,80321,22624,441Mention Spans122,98312,21415,007Unique Entities41,0585,4155,625Unique Relations1,291484504Table 2: Linked WikiText-2 Corpus Statistics.Even with these omissions and mistakes, it is clearthat the annotations are rich and detailed, with ahigh coverage, and thus should prove beneﬁcial fortraining knowledge graph language models.Dataset Statistics Statistics for Linked WikiText-2are provided in Table 2. In this corpus, more than10% of the tokens are considered entity tokens, i.e.they are generated as factual references to informa-tion in the knowledge graph. Each entity is onlymentioned a few times (less than 5 on average, witha long tail), and with more than thousand differentrelations. Thus it is clear that regular languagemodels would not be able to generate factual text,and there is a need for language models to be ableto refer to external sources of information.Differences from WikiText-2Although ourdataset is designed to closely replicate WikiText-2,there are some differences that prevent direct com-parison. Firstly, there are minor variations in textacross articles due to edits between download dates.Secondly, according to correspondence with Merityet al. (2017), WikiText-2 was collected by queryingthe Wikipedia Text API. Because this API discardsuseful annotation information (e.g. article links),Linked WikiText-2 instead was created by directlyfrom the article HTML.\f59674Training and Inference for KGLMIn this section, we describe the training and infer-ence algorithm for KGLM.Pretrained KG Embeddings During evaluation,we may need to make predictions on entities andrelations that have not been seen during training.Accordingly, we use ﬁxed entity and relations em-beddings pre-trained using TransE (Bordes et al.,2013) on Wikidata. Given (p, r, e), we learn em-beddings vp, vr and ve to minimize the distance:δ(vp, vr, ve) = ∥vp + vr −ve∥2 .We use a max-margin loss to learn the embeddings:L = max\u00000, γ + δ (vp, vr, ve) −δ\u0000v′p, vr, v′e\u0001\u0001where γ is the margin, and either p′ or e′ is a ran-domly chosen entity embedding.Training with Linked WikiText-2 Although thegenerative process in KGLM involves many steps,training the model on Linked WikiText-2 is straight-forward. Our loss objective is the negative log-likelihood of the training data:ℓ(Θ) =Xtlog p(xt, Et|x<t, E<t; Θ),where Θ is the set of model parameters. Note thatif an annotation has multiple viable parents such asGame Boy in 1, then we marginalize over all of theparents. Since all random variables are observed,training can performed using off-the-shelf gradient-based optimizers.Inference While observing annotations makes themodel easy to train, we do not assume that themodel has access to annotations during evaluation.Furthermore, as discussed in Section 2.2, the goalin language modelling is to measure the marginalprobability p(x) = PE p(x, E) not the joint proba-bility. However, this sum is intractable to computedue to the large combinatorial space of possibleannotations. We address this problem by approxi-mating the marginal distribution using importancesampling. Given samples from a proposal distribu-tion q(E|x) the marginal distribution is:p(x) =XEp (x, E) =XEp (x, E)q (E|x) q (E|x)≈1NXE∼qp (x, E)q (E|x)This approach is used to evaluate models in Ji et al.(2017) and Dyer et al. (2016). Following Ji et al.(2017), we compute q (E|x) using a discriminativeversion of our model that predicts annotations forthe current token instead of for the next token.5ExperimentsTo evaluate the proposed language model, weﬁrst introduce the baselines, followed by an evalua-tion using perplexity of held-out corpus, accuracyon fact completion, and an illustration of how themodel uses the knowledge graph.5.1Evaluation SetupBaseline Models We compare KGLM to the fol-lowing baseline models:• AWD-LSTM (Merity et al., 2018):strongLSTM-based model used as the foundation ofmost state-of-the-art models on WikiText-2.• ENTITYNLM (Ji et al., 2017): an LSTM-basedlanguage model with the ability to track entitymentions. Embeddings for entities are created dy-namically, and are not informed by any externalsources of information.• EntityCopyNet: a variant of the KGLM wherett = new for all mentions, i.e.entities areselected from E and entity aliases are copied, butrelations in the knowledge graph are unused.Hyperparameters We pre-train 256 dimensionalentity and relation embeddings for all entitieswithin two hops of the set of entities that occur inLinked WikiText-2 using TransE with margin γ = 1.Weights are tied between all date embeddings andbetween all quantity embeddings to save memory.Following Merity et al. (2018) we use 400 dimen-sional word embeddings and a 3 layer LSTM withhidden dimension 1150 to encode tokens. We alsoemploy the same regularization strategy (DropCon-nect (Wan et al., 2013) + Dropout(Srivastava et al.,2014)) and weight tying approach. However, weperform optimization using Adam (Kingma and Ba,2015) with learning rate 1e-3 instead of NT-ASGD,having found that it is more stable.5.2ResultsPerplexity We evaluate our model using the stan-dard perplexity metric: exp\u00101TPTt=1 log p(xt)\u0011.However, perplexity suffers from the issue that it\f5968PPLUPPENTITYNLM* (Ji et al., 2017)85.4189.2EntityCopyNet*76.1144.0AWD-LSTM (Merity et al., 2018)74.8165.8KGLM*44.188.5Table 3: Perplexity Results on Linked WikiText-2. Re-sults for models marked with * are obtained using im-portance sampling.overestimates the probability of out-of-vocabularytokens when they are mapped to a single UNKtoken. This is problematic for comparing the per-formance of the KGLM to traditional languagemodels on Linked WikiText-2 since there are a largenumber of rare entities whose alias tokens are out-of-vocabulary. That is, even if the KGLM identiﬁesthe correct entity and copies the correct alias tokenwith high probability, other models can attain bet-ter perplexity by assigning a higher probability toUNK. Accordingly, we also measure unknown pe-nalized perplexity (UPP) (a.k.a adjusted perplexity)introduced by Ueberla (1994), and used recentlyby Ahn et al. (2016) and Spithourakis and Riedel(2018). This metric penalizes the probability ofUNK tokens by evenly dividing their probabilitymass over U, the set of tokens that get mappedto UNK . We can be compute UPP by replacingp(UNK) in the perplexity above by1|U|p(UNK),where |U| is estimated from the data.We present the model perplexities in Table 3. Tomarginalize over annotations, perplexities for theENTITYNLM, EntityCopyNet, and KGLM are es-timated using the importance sampling approachdescribed in Section 4. We observe that the KGLMattains substantially lower perplexity than the otherentity-based language models (44.1 vs. 76.1/85.4),providing strong evidence that leveraging knowl-edge graphs is crucial for accurate language mod-eling. Furthermore, KGLM signiﬁcantly outper-forms all models in unknown penalized perplexity,demonstrating its ability to generate rare tokens.Fact Completion Since factual text generationis our primary objective, we evaluate the abilityof language models to complete sentences withfactual information. We additionally compare withthe small GPT-2 (Radford et al., 2019), a languagemodel trained on a much larger corpus of text. Weselect 6 popular relations from Freebase, and writea simple completion template for each, such as “Xwas born in” for the birthplace relation. WeAWD-LSTMGPT-2KGLMOracleNELnation-capital0 / 06 / 70 / 00 / 4birthloc0 / 914 / 1494 / 9585 / 92birthdate0 / 258 / 965 / 6861 / 67spouse0 / 02 / 32 / 21 / 19city-state0 / 1362 / 629 / 594 / 59book-author0 / 20 / 061 / 6225 / 28Average0.0/8.215.3/15.838.5/47.729.3/44.8Table4:FactCompletion.Top-kaccuracy(@1/@5,%) for predicting the next token for an incom-plete factual sentence. See examples in Table 5.generate sentences for these templates for a numberof (X, Y ) pairs for which the relation holds, andmanually examine the ﬁrst token generated by eachlanguage model to determine whether it is correct.Table 4 presents performance of each languagemodel on the relations. The oracle KGLM is giventhe correct entity annotation for X, while the NELKGLM uses the discriminative model used for im-portance sampling combined with the NEL entitylinker to produce an entity annotation for X.Amongst models trained on the same data, bothKGLM variants signiﬁcantly outperform AWD-LSTM; they produce accurate facts, while AWD-LSTM produced generic, common words. KGLMsare also competitive with models trained on ordersof magnitude more data, producing factual com-pletions that require speciﬁc knowledge, such asbirthplaces, dates, and authors. However, they donot capture facts or relations that frequently appearin large corpora, like the cities within states.3 It isencouraging to see that the KGLM with automaticlinking performs comparably to oracle linking.We provide examples in Table 5 to highlightqualitative differences between KGLM, trained on600 documents, and the recent state-of-the-art lan-guage model, GPT-2, trained on the WebText cor-pus with over 8 million documents (Radford et al.,2019). For examples that both models get factu-ally correct or incorrect, the generated tokens byKGLM are often much more speciﬁc, as opposedto selection of more popular/generic tokens (GPT-2often predicts “New York” as the birthplace, evenfor popular entities). KGLM, in particular, getsfactual statements correct when the head or tail en-tities are rare, while GPT-2 can only complete factsfor more-popular entities while using more-generictokens (such as “January” instead of “20”).3This is not a failure of the KG, but of the model’s abilityto pick the correct relation from the KG given the prompt.\f5969Input SentenceGoldGPT-2KGLMBoth correctParis Hilton was born inNew York CityNew1981Arnold Schwarzenegger was born on1947-07-30July30KGLM correctBob Dylan was born inDuluthNewDuluthBarack Obama was born on1961-08-04JanuaryAugustUlysses is a book that was written byJames JoyceaJamesGPTv2 correctSt. Louis is a city in the state ofMissouriMissouriOldhamRichard Nixon was born on1913-01-09January20Kanye West is married toKim KardashianKimtheBoth incorrectThe capital of India isNew DelhitheaMadonna is married toCarlos LeonaAlexTable 5: Completion Examples. Examples of fact completion by KGLM and GPT-2, which has been trained ona much larger corpus. GPT-2 tends to produce very common and general tokens, such as one of a few popularcities to follow “born in”. KGLM sometimes makes mistakes in linking to the appropriate fact in the KG, however,the generated facts are more speciﬁc and contain rare tokens. We omit AWD-LSTM from this ﬁgure as it rarelyproduced tokens apart from the generic “the” or “a”, or “⟨UNK⟩”.Effect of changing the KG For most languagemodels, it is difﬁcult to control their generationsince factual knowledge is entangled with gener-ation capabilities of the model. For KGLM, anadditional beneﬁt of its use of an external sourceof knowledge is that KGLM is directly control-lable via modiﬁcations to the KG. To illustrate thiscapability with a simple example, we create com-pletion of “Barack Obama was born on” withthe original fact (Barack Obama, birthDate, 1961-08-04), resulting in the top three decoded tokensas “August”, “4”, “1961”. After changing the birthdate to 2013-03-21, the top three decoded tokensbecome “March”, “21”, “2013”. Thus, changingthe fact in the knowledge graph directly leads to acorresponding change in the model’s prediction.6Related WorkKnowledge-based language models Our workdraws inspiration from two existing knowledge-based language models:(i) ENTITYNLM (Ji et al., 2017) which im-proves a language model’s ability to track entitiesby jointly modeling named entity recognition andcoreference. Our model similarly tracks entitiesthrough a document, improving its ability to gener-ate factual information by modeling entity linkingand relation extraction.(ii) The neural knowledge language model(NKLM) (Ahn et al., 2016) which established theidea of leveraging knowledge graphs in neural lan-guage models. The main differentiating factor be-tween the KGLM and NKLM is that the KGLMoperates on an entire knowledge graph and can beevaluated on text without additional conditioninginformation, whereas the NKLM operates on a rel-atively smaller set of predeﬁned edges emanatingfrom a single entity, and requires that entity be pro-vided as conditioning information ahead of time.This requirement precludes direct comparison be-tween NKLM and the baselines in Section 5.Data-to-text generation Our work is also relatedto the task of neural data-to-text generation. Fora survey of early non-neural text generation meth-ods we refer the reader to Reiter and Dale (1997).Recent neural methods have been applied to gener-ating text from tables of sports statistics (Wisemanet al., 2017), lists and tables (Yang et al., 2017), andWikipedia info-boxes (Lebret et al., 2016). The pri-mary difference between these works and ours isour motivation. These works focus on generatingcoherent text within a narrow domain (e.g. sports,recipes, introductory sentences), and optimize met-rics such as BLEU and METEOR score. Our focusinstead is to use a large source of structured knowl-edge to improve language model’s ability to handlerare tokens and facts on a broad domain of topics,and our emphasis is on improving perplexity.General language modeling Also related are therecent papers proposing modiﬁcations to the AWD-LSTM that improve performance on Wikitext-2 (Gong et al., 2018; Yang et al., 2018; Krauseet al., 2018). We chose to benchmark against AWD-LSTM since these contributions are orthogonal,and many of the techniques are compatible withthe KGLM. KGLM improves upon AWD-LSTM,and we expect using KGLM in conjunction withthese methods will yield further improvement.\f59707Conclusions and Future WorkBy relying on memorization, existing languagemodels are unable to generate factually correct textabout real-world entities. In particular, they areunable to capture the long tail of rare entities andword types like numbers and dates. In this work,we proposed the knowledge graph language model(KGLM), a neural language model that can accessan external source of facts, encoded as a knowledgegraph, in order to generate text. Our implementa-tion is available at: https://github.com/rloganiv/kglm-model. We also introduced Linked WikiText-2 containing text that has been aligned to facts inthe knowledge graph, allowing efﬁcient trainingof the model. Linked WikiText-2 is freely avail-able for download at: https://rloganiv.github.io/linked-wikitext-2. In our evaluation, we showedthat by utilizing this graph, the proposed KGLMis able to generate higher-quality, factually correcttext that includes mentions of rare entities and spe-ciﬁc tokens like numbers and dates.This work lays the groundwork for future re-search into knowledge-aware language modeling.The limitations of the KGLM model, such as theneed for marginalization during inference and re-liance on annotated tokens, raise new research prob-lems for advancing neural NLP models. Our dis-tantly supervised approach to dataset creation canbe used with other knowledge graphs and otherkinds of text as well, providing opportunities foraccurate language modeling in new domains.AcknowledgementsFirst and foremost, we would like to thank StephenMerity for sharing the materials used to collect theWikiText-2 dataset, and Nitish Gupta for modify-ing his entity linker to assist our work. We wouldalso like to thank Dheeru Dua and Anthony Chenfor their thoughtful feedback. This work was sup-ported in part by Allen Institute of Artiﬁcial In-telligence (AI2), and in part by NSF award #IIS-1817183. The views expressed are those of theauthors and do not reﬂect the ofﬁcial policy or po-sition of the funding agencies.ReferencesSungjin Ahn, Heeyoul Choi, Tanel Pärnamaa, andYoshua Bengio. 2016. A neural knowledge languagemodel. ArXiv:1608.00318.Antoine Bordes, Nicolas Usunier, Alberto Garcia-Duran, Jason Weston, and Oksana Yakhnenko.2013. Translating embeddings for modeling multi-relational data. In Proc. of NeurIPS.Chris Dyer, Adhiguna Kuncoro, Miguel Ballesteros,and Noah A. Smith. 2016. Recurrent neural networkgrammars. In Proc. of NAACL.Thiago Castro Ferreira, Diego Moussallem, EmielKrahmer, and Sander Wubben. 2018. Enriching theWebNLG corpus. In Proc. of INLG.Claire Gardent, Anastasia Shimorina, Shashi Narayan,and Laura Perez-Beltrachini. 2017. The WebNLGchallenge: Generating text from RDF data. In Proc.of INLG.Chengyue Gong, Di He, Xu Tan, Tao Qin, Liwei Wang,and Tie-Yan Liu. 2018. Frage: frequency-agnosticword representation. In Proc. of NeurIPS.Jiatao Gu, Zhengdong Lu, Hang Li, and Victor O.K.Li. 2016.Incorporating copying mechanism insequence-to-sequence learning. In Proc. of ACL.Nitish Gupta, Sameer Singh, and Dan Roth. 2017. En-tity linking via joint encoding of types, descriptions,and context. In Proc. of EMNLP.Sepp Hochreiter and Jürgen Schmidhuber. 1997.Long short-term memory.Neural computation,9(8):1735–1780.Yangfeng Ji, Chenhao Tan, Sebastian Martschat, YejinChoi, and Noah A. Smith. 2017.Dynamic entityrepresentations in neural language models. In Proc.of EMNLP.Diederik P. Kingma and Jimmy Ba. 2015.Adam:A method for stochastic optimization. In Proc. ofICLR.Ben Krause, Emmanuel Kahembwe, Iain Murray, andSteve Renals. 2018. Dynamic evaluation of neuralsequence models. In Proc. of ICML.Rémi Lebret, David Grangier, and Michael Auli. 2016.Neural text generation from structured data withapplication to the biography domain.In Proc. ofEMNLP.Stephen Merity, Nitish Shirish Keskar, and RichardSocher. 2018. Regularizing and optimizing LSTMlanguage models. In Proc. of ICLR.Stephen Merity, Caiming Xiong, James Bradbury, andRichard Socher. 2017. Pointer sentinel mixture mod-els. In Proc. of ICLR.\f5971Tomáš Mikolov, Martin Karaﬁát, Lukáš Burget, JanˇCernock`y, and Sanjeev Khudanpur. 2010. Recurrentneural network based language model. In Proc. ofINTERSPEECH.Alec Radford, Jeff Wu, Rewon Child, David Luan,Dario Amodei, and Ilya Sutskever. 2019. Languagemodels are unsupervised multitask learners. Techni-cal report, OpenAI.Ehud Reiter and Robert Dale. 1997. Building appliednatural language generation systems. Natural Lan-guage Engineering, 3(1):57–87.Iulian V. Serban, Alessandro Sordoni, Yoshua Bengio,Aaron Courville, and Joelle Pineau. 2016. Buildingend-to-end dialogue systems using generative hierar-chical neural network models. In Proc. of AAAI.Georgios P. Spithourakis and Sebastian Riedel. 2018.Numeracy for language models: Evaluating and im-proving their ability to predict numbers. In Proc. ofACL.Nitish Srivastava, Geoffrey Hinton, Alex Krizhevsky,Ilya Sutskever, and Ruslan Salakhutdinov. 2014.Dropout: a simple way to prevent neural networksfrom overﬁtting. The Journal of Machine LearningResearch, 15(1):1929–1958.Trieu H. Trinh and Quoc V. Le. 2019. Do languagemodels have common sense? In Proc. of ICLR.Joerg Ueberla. 1994.Analysing a simple languagemodelÂ·some general conclusions for languagemodels for speech recognition. Computer Speech &Language, 8(2):153 – 176.Oriol Vinyals and Quoc V. Le. 2015.A neural con-versational model. Proc. of ICML Deep LearningWorkshop.Denny Vrandeˇci´c and Markus Krötzsch. 2014. Wiki-data: A free collaborative knowledgebase. Commu-nications of the ACM, 57(10):78–85.Li Wan, Matthew Zeiler, Sixin Zhang, Yann LeCun,and Rob Fergus. 2013. Regularization of neural net-works using dropconnect. In Proc. of ICML.Sam Wiseman, Stuart M. Shieber, and Alexander M.Rush. 2017. Challenges in data-to-document gener-ation. In Proc. of EMNLP.Zhilin Yang, Zihang Dai, Ruslan Salakhutdinov, andWilliam W Cohen. 2018. Breaking the softmax bot-tleneck: A high-rank RNN language model. In Proc.of ICLR.Zichao Yang, Phil Blunsom, Chris Dyer, and WangLing. 2017. Reference-aware language models. InProc. of EMNLP.",
        "answer": "The top-1 accuracy of the Oracle KGLM on birthdate prediction is 65%.",
        "space_key_index": 3,
        "metadata": {
            "format": "PDF 1.3",
            "title": "Barack's Wife Hillary: Using Knowledge Graphs for Fact-Aware Language Modeling",
            "author": "Robert Logan ; Nelson F. Liu ; Matthew E. Peters ; Matt Gardner ; Sameer Singh",
            "subject": "P19-1 2019",
            "keywords": "",
            "creator": "LaTeX with hyperref package",
            "producer": "GPL Ghostscript 9.18",
            "creationDate": "D:20190604063539Z00'00'",
            "modDate": "D:20190604063539Z00'00'",
            "trapped": "",
            "encryption": null
        }
    },
    {
        "question": "How many categories of aggression were participants asked to classify texts into?",
        "context": "Proceedings of the First Workshop on Trolling, Aggression and Cyberbullying, pages 1–11Santa Fe, USA, August 25, 2018.1Benchmarking Aggression Identiﬁcation in Social MediaRitesh Kumar1, Atul Kr. Ojha2, Shervin Malmasi3, Marcos Zampieri41Bhim Rao Ambedkar University, 2Jawaharlal Nehru University,3Harvard Medical School, 4University of Wolverhampton,AbstractIn this paper, we present the report and ﬁndings of the Shared Task on Aggression Identiﬁcationorganised as part of the First Workshop on Trolling, Aggression and Cyberbullying (TRAC - 1)at COLING 2018. The task was to develop a classiﬁer that could discriminate between OvertlyAggressive, Covertly Aggressive, and Non-aggressive texts. For this task, the participants wereprovided with a dataset of 15,000 aggression-annotated Facebook Posts and Comments each inHindi (in both Roman and Devanagari script) and English for training and validation. For testing,two different sets - one from Facebook and another from a different social media - were provided.A total of 130 teams registered to participate in the task, 30 teams submitted their test runs,and ﬁnally 20 teams also sent their system description paper which are included in the TRACworkshop proceedings. The best system obtained a weighted F-score of 0.64 for both Hindi andEnglish on the Facebook test sets, while the best scores on the surprise set were 0.60 and 0.50for English and Hindi respectively. The results presented in this report depict how challengingthe task is. The positive response from the community and the great levels of participation in theﬁrst edition of this shared task also highlights the interest in this topic.1IntroductionIn the last decade, with the emergence of an interactive web and especially popular social networkingand social media platforms like Facebook and Twitter, there has been an exponential increase in theuser-generated content being made available over the web. Now any information online has the powerto reach billions of people within a matter of seconds. This has resulted in not only positive exchange ofideas but has also lead to a widespread dissemination of aggressive and potentially harmful content overthe web. While most of the potentially harmful incidents like bullying or hate speech have predated theInternet, the reach and extent of Internet has given these incidents an unprecedented power and inﬂuenceto affect the lives of billions of people. It has been reported that these incidents have not only createdmental and psychological agony to the users of the web but has in fact forced people to deactivate theiraccounts and in extreme cases also commit suicides (Hinduja and Patchin, 2010). Thus the incidents ofaggression and unratiﬁed verbal behaviour have not remained a minor nuisance, but have acquired theform of a major criminal activity that affects a large number of people. It is therefore important thatpreventive measures can be taken to cope with abusive behaviour aggression online.One of the strategies to cope with aggressive behaviour online is to manually monitor and moderateuser-generated content, however, the amount and pace at which new data is being created on the web hasrendered manual methods of moderation and intervention almost completely impractical. As such theuse (semi-) automatic methods to identify such behaviour has become important and has attracted moreattention from the research community in recent years (Davidson et al., 2017; Malmasi and Zampieri,2017).This work is licensed under a Creative Commons Attribution 4.0 International License.License details:http://creativecommons.org/licenses/by/4.0/\f2This paper reports the results of the ﬁrst Shared Task on Aggression Identiﬁcation which was organisedjointly with the First Workshop on Trolling, Aggression and Cyberbullying (TRAC - 1) at COLING 2018.2Related WorkVerbal aggression per se has been rarely explored within the ﬁeld of Natural Language Processing.However, previous research in the ﬁeld has been carried out to automatically recognise several relatedbehaviour such as trolling (Cambria et al., 2010; Kumar et al., 2014; Mojica, 2016; Mihaylov et al.,2015) , cyberbullying (Dinakar et al., 2012; Nitta et al., 2013; Dadvar et al., 2013; Dadvar et al., 2014;Hee et al., 2015), ﬂaming / insults (Sax, 2016; Nitin et al., 2012), abusive / offensive language (Chen etal., 2012; Nobata et al., 2016; Waseem et al., 2017), hate speech (Pinkesh Badjatiya and Varma, 2017;Burnap and Williams, 2014; Davidson et al., 2017; Vigna et al., 2017; Djuric et al., 2015; Fortana,2017; Gitari et al., 2015; Malmasi and Zampieri, 2018; Waseem and Hovy, 2016; Schmidt and Wie-gand, 2017), radicalization (Agarwal and Sureka, 2015; Agarwal and Sureka, 2017), racism (Greevy andSmeaton, 2004; Greevy, 2004) and others. In addition to these, there have been some pragmatic studieson behaviour like trolling (Hardaker, 2010; Hardaker, 2013).This huge interest in the ﬁeld from different perspectives has created a conglomeration of terminolo-gies as well as understandings of the phenomenon. On the one hand, this provides us with a very richand extensive insight into the phenomena yet, on the other hand, it has also created a theoretical gapin the understanding of interrelationship among these. Moreover, it has also resulted in duplication ofresearch, to certain extent, and a certain kind of lack of focus and reusability of datasets across differentstrands of research. In order to make improvements towards solving a complex phenomenon like this,it is of utmost importance that some kind of uniform understanding of problem be achieved so that, atleast, standardised datasets and an understanding of different approaches to solving the problem may bedeveloped.While a large part of the research has focused on any one of these phenomena and their computationalprocessing, it seems there is a signiﬁcant overlap among these phenomenon in the way they are under-stood in these studies - and because of this underlying overlap, insights from different studies mightprove useful for solving these seemingly different phenomena. All of these behaviours are consideredundesirable, aggressive and detrimental for those on the receiving end. So, trolling is intended “to causedisruption and/or to trigger or exacerbate conﬂict for the purposes of their own amusement” (Hardaker,2010). Cyberbullying is “humiliating and slandering behavior towards other people” (Nitta et al., 2013).Flaming intends “to offend someone through e-mail, posting, commenting or any statement using insults,swearing and hostile, intense language, trolling, etc.” (Krol, 1992).Waseem et al. (2017) makes an attempt to unify these different trends of research in what may be con-sidered a signiﬁcantly overlapping ﬁeld and proposes a 2-way typology for understanding what they call’abusive language’ over the web. They propose 2 scales on which abusive language could be categorised- the target of the abuse (an individual or a group) and the nature of the language (explicit or implicit).Our classiﬁcation of aggression into overt and covert aggression is largely similar to the explicit-implicitdistinction. However, we make a more detailed distinction in relation to the target of the abuse (Kumaret al., 2018b) and it is not made along the axis of individual vs. group. This is so because we noticedin a large number of instances both individuals and groups are simultaneously targeted - in such casesindividuals are targeted as members of certain groups or the individuals’ actions were considered thoseof the group and became the locus of attack. As such it was not feasible to distinguish between theindividual and group attack in lot of instances while annotating the dataset. The distinction that we madewas related to the “locus” of attack and included such targets as gender, religion, caste, country of origin,race, etc. This classiﬁcation, on the one hand, gave scope for focusing on different kinds of attack (forexample, racial attacks or communal attacks) and, on the other hand, each of these targets may actuallybe attacked using a different set of vocabulary, thereby, making these more natural classes that could beclassiﬁed using the surface-level linguistic features. Of course, it cannot be denied that these targets arenot mutually exclusive and, as such, it makes the problem not just a multi-class classiﬁcation problembut also multi-label classiﬁcation problem. In addition to this, we also make use of a different terminol-\f3ogy taking into account its use within socio-pragmatics. This was done with an understanding that hugeamount of literature within the ﬁeld of aggression and impoliteness studies might be able to contributeand provide insights to understanding the phenomenon in a better way.The aim of this shared task was much simpler than the one discussed in the previous para. It onlyinvolved classiﬁcation of the texts into 3 categories - overt aggression, covert aggression and non-aggression. We wanted to use the dataset for experimenting with different approaches to make the mosttop-level classiﬁcation of aggression on social media.3Task Setup and ScheduleThe participants interested in competing in the shared task were required to register using a Google Form.The form gave them an option to participate for either English or Hindi or both the languages. All theregistered participants were sent the links to the annotated dataset in the language(s) of their choice, alongwith a description of the format of the dataset. The participants were allowed to use additional data fortraining the system, with the condition that the additional dataset should be either publicly available ormake available immediately after submission (and well before the submission of the system papers) andthis must be mentioned in the submission. Use of non-public additional data for training was not allowed.The participants were given around 6 weeks to experiment and develop the system. However, since morethan half of the participants registered after the ﬁrst release of the data, most of them got less time thanthis. Initially, the dataset was not released publicly but was emailed only to the registered participants.After the 6 weeks of release of train and dev sets, the test set was released and the participants had 5 daysto test and upload their system. The complete timeline of the shared task is given in Table 1. We madeuse of CodaLab 1 for the evaluation. Each team was allowed to submit up to 3 systems for evaluation.We used the best of the 3 runs for the ﬁnal ranking and evaluation of the systems.DateEvent1 February, 2018Shared Task Announcement and Start of Registration13 March, 2018Release of train and dev sets25 April, 2018Release of test set30 April, 2018Deadline for Submission of System2 May, 2018Declaration of Results28 May, 2018Deadline for Submission of System Description PaperTable 1: Timeline of the Aggression Identiﬁcation Shared Task at TRAC - 1.4DatasetThe participants of the shared task were provided with a dataset of 12,000 randomly sampled Face-book comments for training and 3,000 comments for development and in English and Hindi each, an-notated with 3 levels of aggression - Overtly Aggressive (OAG), Covertly Aggressive (CAG) and Non-Aggressive (NAG). For test, 916 English comments and 970 Hindi comments were provided. Addi-tionally, 1,257 English tweets and 1,194 Hindi tweets were given as the surprise test set 2. The datasetreleased for the task is a subset of a larger dataset discussed in Kumar et al. (2018b).4.1Issues with the DatasetWhile most of the participants considered the dataset to be of high quality, two major problems came upduring the task -• The language issue: Some of the comments in English dataset contained code-mixed Hindi-Englishdata as well as data from other languages like German. These formed a minuscule proportion of thedata but nevertheless these need to be ﬁltered out.1https://competitions.codalab.org/2The complete dataset used for the shared task can be downloaded here - http://trac1-dataset.kmiagra.org/\f4• The annotation issue: The second and more serious issue that was raised by some participantsis related to the the annotation itself. Several instances of supposedly inaccurate annotation werepointed out. Despite the fact that aggression is a highly subjective phenomenon and different anno-tators may have different judgments about the same comment, some of the annotation indeed lookedhighly implausible and consequently it needs further scrutiny and validation.5Participants and ApproachesThe shared task gave the participants an option to register for either one of the two languages - Englishor Hindi - or both. A total of 131 participants registered for the shared task, with 73 teams registeringto participate only in English track, 2 teams only in Hindi track and 56 teams registered to participatein both the tracks. Out of these, ﬁnally a total of 30 teams submitted their systems - 15 teams for bothEnglish and Hindi and 30 teams for only English track. All the systems who submitted their systemwere invited to submit the system description paper, describing the experiments conducted by them. 18participants submitted the ﬁnal description paper which are included in the workshop proceedings - itincluded papers by majority of the top 10 teams. Table 2, lists the participating teams and the languagethey took part in.TeamHindiEnglishSystem Description Papersaroyehun✓(Aroyehun and Gelbukh, 2018)EBSI-LIA-UNAM✓(Arroyo-Fern´andez et al., 2018)DA-LD-Hildesheim✓✓(Modha et al., 2018)TakeLab✓(Golem et al., 2018)sreeIN✓(Madisetty and Desarkar, 2018)Julian✓✓(Risch and Krestel, 2018)taraka rama✓✓uOttawa✓(Orabi et al., 2018)Isistanitos✓(Tommasel et al., 2018)hakuchumu✓DataGeeks✓✓na14✓✓(Samghabadi et al., 2018)dinel✓(Orasan, 2018)vista.ue✓✓(Raiyani et al., 2018)MANITBHOPALINDIA✓✓IRIT✓(Ramiandrisoa and Mothe, 2018)quine✓✓(Nikhil et al., 2018)IIIT-Delhi✓PMRS✓✓(Maitra and Sarkhel, 2018)resham✓✓IreneR✓Nestor✓✓UAEMex-UAPT1✓✓forest and trees✓(Galery et al., 2018)groutar✓(Fortuna et al., 2018)Shusrut✓✓(Roy et al., 2018)malaypramanick✓UAEMex-UAPT-TAC2✓✓Unito✓✓bhanodaig✓(Kumar et al., 2018a)Total153018Table 2: The teams that participated in the Aggression Identiﬁcation Shared Task at TRAC - 1.Next we give a short description of the approach taken by each team for building their system. Moredetails about the approaches could be found in the paper submitted by the respective teams.\f5• saroyehun system gives the best performance with LSTM and they resorted to translation as dataaugmentation strategy. With the surprise twitter set, a combination of the representations of theRNN and CNN as features, along with additional preprocessing like spelling correction, translationof emoji, and computation of sentiment score gave the best performance. In this case, the datasetwas also augmented using translation and pseudolabelled using an external dataset on hate speech.3This is the only approach in the competition that performs better on the Twitter dataset, despitebeing trained the Facebook dataset, thereby, depicting the ability of the approach to generaliseacross domain.• EBSI-LIA-UNAM system uses a combination of the Passive-Aggressive (PA) and SVM classiﬁerswith character based n-gram (1 - 5 grams) TF-IDF for feature representation.• DA-LD-Hildesheim uses LSTM with pretrained Fasttext vector for embeddings for classifyingEnglish Facebook texts. For all other datasets including Twitter data in English and both Facebookand Twitter dataset in Hindi, CNN performs better.• TakeLab uses a Bidirectional LSTM on Glove embeddings to give the best performance.• sreeIN system uses a voting-based ensemble method with 3 classiﬁers - CNN with 4 layers, LSTMand Bidirectional LSTM.• Julian team uses translation as data augmentation strategy and use an ensemble of TF-IDF basedapproaches, using character n-grams (2 - 6) and word n-grams (1 - 2) with a bi-directional RNN,using fasttext embeddings, to get the best performance in the task..• taraka rama uses different systems for different datasets. For English Facebook dataset and HindiTwitter dataset, the team uses a stacked ensemble classiﬁer that uses a SVM on top of the ensembleof SVM classiﬁers. The SVMs were trained on 1 - 6 character n-grams and word unigrams. ForHindi Facebook and English Twitter dataset, however, a plain SVM trained using character and wordbag-of-n-grams gave the best performance. In this case, the overlapping character and word n-gramfeatures are weigthed with sublinear tf-idf before being used for training and testing. The systemis tuned using 5-fold CV on the combined training and develpment sets for maximum numberof character and word n-grams included, case normalization, and SVM margin (regularization)parameter C.• uOttawa system is trained using a novel deep-learning architecture for text classiﬁcation based onMulti-task learning (MTL). The approach, MTL, is evaluated using three neural network models.MultiCNN, multiple convolution structure with a trainable embedding layer, gives the best perfor-mance.• Isistanitos system uses a soft voting (average the class probabilities of other models) of two models- a recurrent neural network, and an SVM. The recurrent neural network uses 3 preprocesed setof features. The ﬁrst set uses an ad-hoc glove model for representing the words, the second isa sentiwornet based model, and the third is a traditional TfIdf plus Vader Sentiment analysis andsentiments associated with the emojis. The SVM model is trained on a TF-IDF of the post stemmedterms, excluding stopwords, and 3 - 5 character n-grams.• hakuchumu system makes use of a Random Forest classiﬁer with some preprocessing includingremoval of urls and non letter characters and stop words. Along with the bag-of-word, the approachuses multiple occurrences of letters, exclamation marks and question marks in a row and emoticonsas binary features.• DataGeeks system uses Logistic Regression classiﬁer with some preprocessing on the data suchas removing non-ascii characters, replacing new line with ’.’, replacing n’t with not, removingstopwords and 1 - 3 word n-grams and 2 - 6 character n-grams for training the classiﬁer.3https://github.com/ZeerakW/hatespeech\f6• na14 also uses Logistic Regression classiﬁer with preprocessing involving replacing URLs, num-bers, email addresses and spelling correction. The classiﬁer is trained using word unigrams, tf-idfvectors of word unigram, character 4-gram, character 5-gram and Google news pre-trained wordembedding model. For the Hindi dataset, Devanagari texts were transliterated into Roman at thepreprocessing stage.• dinel achieves the best accuracy on the Facebook test set using a Random Forest classiﬁer whileSVMs performed better for the surprise Twiiter test set. Both the classiﬁers were trained using 300semantic features which represent the vector representation of the text, average scores of the topemojis for each of the classes and positive and negative sentiment scores.• vista.ue system is developed using dense neural networks.• MANITBHOPALINDIA system for English is developed using SVM while for English it is trainedusing deep neural networks.• IRIT system gets the best performance for the English Facebook test set by using a combination oftwo models - a doc2vec model and a logistic regression classiﬁer. For the Twitter test set, it uses acombination of CNN and LSTM to get the best performance.• quine system is trained using an LSTM with attention and simple embeddings (word to index)instead of pre-trained embeddings.• IIIT-Delhi system uses a Single channel CNN for this task. Bayesian Optimization is used fortuning the parameters.• PMRS system employs a winner-takes- all autoencoder, called Emoti-KATE for Twitter senti-ment classiﬁcation. Each input dimension of Emoti-KATE is a log-normalized, sentiwordnet-scoreweighted word-count vector. A binary cross-entropy loss function is used to train the network.• resham system for English has been made using an open vocabulary approach and ensemble modelof two predictors with soft voting. The ﬁrst predictor is a Naive Bayes model with CountVectorizerfor preprocessing. The second predictor is a recurrent neural network with one embedding layerand two LSTM layers. Pre-trained word vectors have been used for the embedding layer. For Hindidataset, a Naive Bayes classiﬁer is trained using the dataset augmented with English translations.• IreneR system is based on a Multinomial Naive Bayes classiﬁer that uses unigrams, bigrams,hedging bigrams and trigrams such as ’do you’, someone who is’,’to see that’, that potentiallysignal covert aggressivity, identiﬁed with chi-squared test as features. It also includes features fromLIWC2015 (list of anger and swear words).• Nestor uses an approach that combines Neural Networks and a new word representation model.The patterns obtained from the word model representation are used for training the back propa-gation neural network with ﬁx parameters. The length of the post was ﬁxed and the word modelrepresentation is language independent, so it was used for both the English and the Hindi tasks.• UAEMex-UAPT1 uses the same approach as used by the team Nestor.• forest and trees system uses a Pooled Recurrent Unit architecture combined with pre-trained En-glish and Hindi fasttext word embeddings as a representation of the sequence input. In this approach,Hindi and English vectors were aligned using pre-computed SVD matrices that pulls representationsfrom different languages into a single space. This enabled the same model to be used for both thelanguages, thereby, making data re-utilization and model deployability easier.• groutar system is trained using random forests. The dataset is augmented with an external toxicitydataset 4. The approach involved understanding the effects of new data on aggression identiﬁcation.4https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge\f7• Shusrut system uses an ensemble of CNN 2D with MAXPOOL classiﬁer and a SVM classiﬁer. Theensemble model is passed through 3 dense layers to ﬁnally predict the output. Softmax activation isused in the outer layer for classiﬁcation.• malaypramanick system uses a random forest classiﬁer trained using a set of surface-level fea-tures including number of line,s uppercase and lowercase letters, digits, named entities, unicodecharacters, etc.• UAEMex-UAPT-TAC2 system is generated by combination of twelve distance measures, througha K Nearest Neighbors classiﬁcation algorithm and a canonical genetic algorithm.• Unito is the only unsupervised system submitted in the task. It is based only on a multilinguallexicon of aggressive words. The lexicon is obtained by automatic translation from an handmadelexicon of offensive words in Italian, with minimal human supervision. The original words areexpanded into a list of their senses. The senses are manually annotated to ﬁlter out senses that arenever used in an offensive context. Finally, all the lemmas of the remaining senses are generatedwith BabelNet in 50+ languages. The words in the lexicon are divided in those translating sense thatcan be used in an offensive context (but not necessarily are) and words translating senses that aredirectly offensive. This distinction is mapped to the Overtly Aggressive and Covertly Aggressiveclasses respectively. The classiﬁcation of sentences is straightforward: a sentence that does notcontain any word from the lexicon is tagged as NAG, a sentence containing more directly offensivewords than potentially offensive words is tagged as OAG, and the other cases are tagged as CAG.• bhanodaig system uses a bidirectional LSTM.6ResultsIn this section, we present the results of the experiments carried out by different teams during the sharedtask. The results of the top 15 teams on English dataset is given in Figure 1 and that on Hindi dataset isin Figure 2.Figure 1: Performance of top 15 teams on English Dataset\f8The participants were allowed to use other datasets, in addition to the one provided by the organizers ofthe task. However, because of the lack of similar alternative datasets, all the groups, except ’groutar’ and’saroyehun’ team, used only the dataset provided for the task. As we mentioned earlier, the participantswere given two kinds of test sets for the ﬁnal testing of the system - one from Facebook and a surprisetest set from Twitter.Figure 2: Performance of teams on Hindi Dataset7ConclusionIn this paper, we have presented the report of the First Shared task on Aggression Identiﬁcation organizedwith the TRAC workshop at COLING 2018. The shared task received a very encouraging response fromthe community which underlines the relevance and need of the task. More than 100 teams registered and30 teams ﬁnally submitted their system.The performance of the best systems in the task show that aggression identiﬁcation is a hard problem tosolve. Moreover, the performance of the neural networks-based systems as well as the other approachesdo not seem to differ much. If the features are carefully selected then classiﬁers like SVM and evenrandom forest and logistic regression perform at par with deep neural networks. On the other had, weﬁnd quite a few neural networks-based systems not performing quite well in the task. Nonetheless, 14systems were trained using one or the other architectures of deep neural networks - either solely or aspart of an ensemble. Moreover, 8 systems out of the top 15 are trained on neural networks, which showsthe efﬁcacy of the approach but at the same time does not rule out the usefulness and relevance of linearmodels for the task. There was only one system, Unito, that made use of a lexicon-based approach tosolve the task. A few participants of the task pointed out the apparent “inconsistencies” in the annotation.It points towards the need to get the annotations validated by multiple human annotators.AcknowledgementsWe would like to thank Microsoft Research India for providing grants to prepare the dataset and to ourannotators who worked very hard to ﬁnish the annotations within a strict deadline.\f9We would also like to thank the participants of the Shared Task for their participation and feedbackand the TRAC workshop PC members for thoroughly reviewing the shared task papers within a veryshort span of time.ReferencesSwati Agarwal and Ashish Sureka. 2015. Using knn and svm based one-class classiﬁer for detecting onlineradicalization on twitter. In International Conference on Distributed Computing and Internet Technology, pages431 – 442. Springer.Swati Agarwal and Ashish Sureka. 2017. Characterizing linguistic attributes for automatic classiﬁcation of intentbased racist/radicalized posts on tumblr micro-blogging website.Segun Taofeek Aroyehun and Alexander Gelbukh. 2018. Aggression detection in social media: Using deepneural networks, data augmentation, and pseudo labeling. In Proceedings of the First Workshop on Trolling,Aggression and Cyberbullying (TRAC – 1), Santa Fe, USA.Ignacio Arroyo-Fern´andez, Dominic Forest, Juan-Manuel Torres-Moreno, Mauricio Carrasco-Ruiz, Thomas Leg-eleux, and Karen Joannette. 2018. Cyber-bullying detection task: the ebsi-lia-unam system (elu) at coling’18trac-1. In Proceedings of the First Workshop on Trolling, Aggression and Cyberbullying (TRAC – 1), Santa Fe,USA.Peter Burnap and Matthew L. Williams. 2014. Hate speech, machine classiﬁcation and statistical modelling ofinformation ﬂows on twitter: Interpretation and communication for policy decision making. In Proceedings ofInternet, Policy & Politics, pages 1 – 18.Erik Cambria, Praphul Chandra, Avinash Sharma, and Amir Hussain. 2010. Do not feel the trolls. In ISWC,Shanghai.Ying Chen, Yilu Zhou, Sencun Zhu, and Heng Xu. 2012. Detecting offensive language in social media to pro-tect adolescent online safety. privacy, security, risk and trust (passat). In International Conference on SocialComputing (SocialCom), pages 71–80.Maral Dadvar, Dolf Trieschnigg, Roeland Ordelman, and Franciska de Jong. 2013. Improving cyberbullyingdetection with user context. In Advances in Information Retrieval, pages 693–696. Springer.Maral Dadvar, Dolf Trieschnigg, and Franciska de Jong. 2014. Experts and machines against bullies: a hybridapproach to detect cyberbullies. In Advances in Artiﬁcial Intelligence, pages 275–281. Springer, Berlin.Thomas Davidson, Dana Warmsley, Michael Macy, and Ingmar Weber. 2017. Automated hate speech detectionand the problem of offensive language. In Proceedings of ICWSM.Karthik Dinakar, Birago Jones, Catherine Havasi Henry Lieberman, and Rosalind Picard. 2012. Common sensereasoning for detection, prevention, and mitigation of cyberbullying. ACM Transactions on Interactive Intelli-gent Systems (TiiS), 2(3):18:1–18:30.Nemanja Djuric, Jing Zhou, Robin Morris, Mihajlo Grbovic, Vladan Radosavljevic, and Narayan Bhamidipati.2015. Hate speech detection with comment embeddings. In Proceedings of the 24th International Conferenceon World Wide Web, pages 29 – 30.Paula Fortana. 2017. Automatic detection of hate speech in text: an overview of the topic and dataset annotationwith hierarchical classes. Master’s thesis, Faculdade de Engenharia da Universidade do Porto.Paula Fortuna, Jos´e Ferreira, Luiz Pires, Guilherme Routar, and S´ergio Nunes. 2018. Merging datasets for aggres-sive text identiﬁcation. In Proceedings of the First Workshop on Trolling, Aggression and Cyberbullying (TRAC– 1), Santa Fe, USA.Thiago Galery, Efstathios Charitos, and Ye Tian. 2018. Aggression identiﬁcation and multi lingual word embed-dings. In Proceedings of the First Workshop on Trolling, Aggression and Cyberbullying (TRAC – 1), Santa Fe,USA.Njagi Dennis Gitari, Zhang Zuping, Hanyurwimfura Damien, and Jun Long. 2015. A lexicon- based approach forhate speech detection. International Journal of Multimedia and Ubiquitous Engineering, 10(4):215 – 230.\f10Viktor Golem, Mladen Karan, and Jan najder. 2018. Combining traditional machine learning models with deeplearning for aggressive text detection. In Proceedings of the First Workshop on Trolling, Aggression and Cyber-bullying (TRAC – 1), Santa Fe, USA.Edel Greevy and Alan F. Smeaton. 2004. Classifying racist texts using a support vector machine. In Proceedingsof the 27th annual international ACM SIGIR conference on Research and development in information retrieval,pages 468 – 469. ACM.Edel Greevy. 2004. Automatic text categorisation of racist webpages. Ph.D. thesis, Dublin City University.Claire Hardaker. 2010. Trolling in asynchronous computer-mediated communication: From user discussions toacademic deﬁnitions. Journal of Politeness Research. Language, Behaviour, Culture, 6(2):215–242.Claire Hardaker. 2013. uh. . . . not to be nitpicky,,,,,but...the past tense of drag is dragged, not drug. an overviewof trolling strategies. Journal of Language Aggression and Conﬂict, 1(1):58–86.Cynthia Van Hee, Els Lefever, Ben Verhoeven, Julie Mennes, Bart Desmet, Guy De Pauw, Walter Daelemans, andVronique Hoste. 2015. Detection and ﬁne-grained classiﬁcation of cyberbullying events. In Proceedings ofInternational Conference Recent Advances in Natural Language Processing (RANLP), pages 672–680.Sameer Hinduja and Justin W Patchin. 2010. Bullying, Cyberbullying, and Suicide. Archives of suicide research,14(3):206–221.E. Krol. 1992. The whole internet: User’s guide & catalog. O’Reilly & Associates, Inc., Sebastopol, CA.Sudhakar Kumar, Francesca Spezzano, and VS Subrahmanian. 2014. Accurately detecting trolls in slashdotzoo via decluttering. In Proceedings of IEEE/ACM International Conference on Advances in Social NetworksAnalysis and Mining (ASONAM), pages 188–195.Ritesh Kumar, Guggilla Bhanodai, Rajendra Pamula, and Maheshwar Reddy Chennuru. 2018a. Trac-1 shared taskon aggression identiﬁcation: Iit(ism)@coling18. In Proceedings of the First Workshop on Trolling, Aggressionand Cyberbullying (TRAC – 1), Santa Fe, USA.Ritesh Kumar, Aishwarya N. Reganti, Akshit Bhatia, and Tushar Maheshwari. 2018b. Aggression-annotated cor-pus of hindi-english code-mixed data. In Nicoletta Calzolari (Conference chair), Khalid Choukri, ChristopherCieri, Thierry Declerck, Sara Goggi, Koiti Hasida, Hitoshi Isahara, Bente Maegaard, Joseph Mariani, HlneMazo, Asuncion Moreno, Jan Odijk, Stelios Piperidis, and Takenobu Tokunaga, editors, Proceedings of theEleventh International Conference on Language Resources and Evaluation (LREC 2018), Paris, France, may.European Language Resources Association (ELRA).Sreekanth Madisetty and Maunendra Sankar Desarkar. 2018. Aggression detection in social media using deepneural networks. In Proceedings of the First Workshop on Trolling, Aggression and Cyberbullying (TRAC – 1),Santa Fe, USA.Promita Maitra and Ritesh Sarkhel. 2018. Emoti-kate: a k-competitive autoencoder for aggression detection insocial media text. In Proceedings of the First Workshop on Trolling, Aggression and Cyberbullying (TRAC – 1),Santa Fe, USA.Shervin Malmasi and Marcos Zampieri. 2017. Detecting Hate Speech in Social Media. In Proceedings of theInternational Conference Recent Advances in Natural Language Processing (RANLP), pages 467–472.Shervin Malmasi and Marcos Zampieri. 2018. Challenges in discriminating profanity from hate speech. Journalof Experimental & Theoretical Artiﬁcial Intelligence, 30:1 – 16.Todor Mihaylov, Georgi D Georgiev, AD Ontotext, and Preslav Nakov. 2015. Finding opinion manipulation trollsin news community forums. In Proceedings of the Nineteenth Conference on Computational Natural LanguageLearning, CoNLL, pages 310–314.Sandip Modha, Prasenjit Majumder, and Thomas Mandl. 2018. Filtering aggression from multilingual socialmedia feed. In Proceedings of the First Workshop on Trolling, Aggression and Cyberbullying (TRAC – 1), SantaFe, USA.Luis G Mojica. 2016. Modeling trolling in social media conversations.Nishant Nikhil, Ramit Pahwa, Mehul Kumar Nirala, and Rohan Khilnani. 2018. Lstms with attention for aggres-sion detection. In Proceedings of the First Workshop on Trolling, Aggression and Cyberbullying (TRAC – 1),Santa Fe, USA.\f11Nitin, Ankush Bansal, Siddhartha Mahadev Sharma, Kapil Kumar, Anuj Aggarwal, Sheenu Goyal, Kanika Choud-hary, Kunal Chawla, Kunal Jain, and Manav Bhasinar. 2012. Classiﬁcation of ﬂames in computer mediatedcommunications.Taisei Nitta, Fumito Masui, Michal Ptaszynski, Yasutomo Kimura, Rafal Rzepka, and Kenji Araki. 2013. Detect-ing cyberbullying entries on informal school websites based on category relevance maximization. In Proceed-ings of IJCNLP, pages 579–586.Chikashi Nobata, Joel Tetreault, Achint Thomas, Yashar Mehdad, and Yi Chang. 2016. Abusive Language Detec-tion in Online User Content. In Proceedings of the 25th International Conference on World Wide Web, pages145–153. International World Wide Web Conferences Steering Committee.Ahmed Husseini Orabi, Mahmoud Husseini Orabi, Qianjia Huang, Diana Inkpen, and David Van Bruwaene. 2018.Cyber-aggression detection using cross segment-and-concatenate multi-task learning from text. In Proceedingsof the First Workshop on Trolling, Aggression and Cyberbullying (TRAC – 1), Santa Fe, USA.Constantin Orasan. 2018. Aggressive Language Identiﬁcation Using Word Embeddings and Sentiment Features.In Proceedings of the First Workshop on Trolling, Aggression and Cyberbullying (TRAC – 1), Santa Fe, USA.Manish Gupta Pinkesh Badjatiya, Shashank Gupta and Vasudeva Varma. 2017. Deep learning for hate speechdetection in tweets. In Proceedings of the 26th International Conference on World Wide Web Companion, pages759 – 760. International World Wide Web Conferences Steering Committee.Kashyap Raiyani, Teresa Gonc¸alves, Paulo Quaresma, and Vitor Beires Nogueira. 2018. Fully connected neuralnetwork with advance preprocessor to identify aggression over facebook and twitter. In Proceedings of the FirstWorkshop on Trolling, Aggression and Cyberbullying (TRAC – 1), Santa Fe, USA.Faneva Ramiandrisoa and Josiane Mothe. 2018. Irit at trac 2018. In Proceedings of the First Workshop on Trolling,Aggression and Cyberbullying (TRAC – 1), Santa Fe, USA.Julian Risch and Ralf Krestel. 2018. Aggression identiﬁcation using deep learning and data augmentation. InProceedings of the First Workshop on Trolling, Aggression and Cyberbullying (TRAC – 1), Santa Fe, USA.Arjun Roy, Prashant Kapil, Kingshuk Basak, and Asif Ekbal. 2018. An ensemble approach for aggression identiﬁ-cation in english and hindi text. In Proceedings of the First Workshop on Trolling, Aggression and Cyberbullying(TRAC – 1), Santa Fe, USA.Niloofar SaﬁSamghabadi, Deepthi Mave, Sudipta Kar, and Thamar Solorio. 2018. Ritual-uh at trac 2018 sharedtask: Aggression identiﬁcation. In Proceedings of the First Workshop on Trolling, Aggression and Cyberbully-ing (TRAC – 1), Santa Fe, USA.Sasha Sax. 2016. Flame Wars: Automatic Insult Detection. Technical report, Stanford University.Anna Schmidt and Michael Wiegand. 2017. A Survey on Hate Speech Detection Using Natural Language Pro-cessing. In Proceedings of the Fifth International Workshop on Natural Language Processing for Social Media.Association for Computational Linguistics, pages 1–10, Valencia, Spain.Antonela Tommasel, Juan Manuel Rodriguez, and Daniela Godoy. 2018. Textual aggression detection throughdeep learning. In Proceedings of the First Workshop on Trolling, Aggression and Cyberbullying (TRAC – 1),Santa Fe, USA.Fabio Del Vigna, Andrea Cimino, Felice DellOrletta, Marinella Petrocchi, and Maurizio Tesconi. 2017. Hate me,hate me not: Hate speech detection on facebook. In Proceedings of the First Italian Conference on Cybersecu-rity, pages 86 – 95.Zeerak Waseem and Dirk Hovy. 2016. Hateful symbols or hateful people? predictive features for hate speechdetection on twitter. In Proceedings of NAACL-HLT, pages 88 – 93.Zeerak Waseem, Thomas Davidson, Dana Warmsley, and Ingmar Weber. 2017. Understanding abuse: A typologyof abusive language detection subtasks. In Proceedings of the First Workshop on Abusive Language Online,pages 78–84. Association for Computational Linguistics.",
        "answer": "3 categories: overt aggression, covert aggression, and non-aggression.",
        "space_key_index": 2,
        "metadata": {
            "format": "PDF 1.3",
            "title": "Benchmarking Aggression Identification in Social Media",
            "author": "Ritesh Kumar ; Atul Kr. Ojha ; Shervin Malmasi ; Marcos Zampieri",
            "subject": "W18-44 2018",
            "keywords": "",
            "creator": "TeX",
            "producer": "pdfTeX-1.40.18",
            "creationDate": "D:20180717122342Z",
            "modDate": "D:20180717122342Z",
            "trapped": "",
            "encryption": null
        }
    },
    {
        "question": "Based on Figure 2, which language exhibited the greatest bias in accuracy between stereotypical and non-stereotypical gender roles when using Google Translate?",
        "context": "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages 1679–1684Florence, Italy, July 28 - August 2, 2019. c⃝2019 Association for Computational Linguistics1679Evaluating Gender Bias in Machine TranslationGabriel Stanovsky1,2, Noah A. Smith1,2, and Luke Zettlemoyer11Paul G. Allen School of Computer Science & Engineering, University of Washington, Seattle, USA2Allen Institute for Artiﬁcial Intelligence, Seattle, USA{gabis,nasmith,lsz}@cs.washington.eduAbstractWe present the ﬁrst challenge set and eval-uation protocol for the analysis of genderbias in machine translation (MT). Our ap-proach uses two recent coreference resolutiondatasets composed of English sentences whichcast participants into non-stereotypical genderroles (e.g., “The doctor asked the nurse to helpher in the operation”). We devise an automaticgender bias evaluation method for eight tar-get languages with grammatical gender, basedon morphological analysis (e.g., the use of fe-male inﬂection for the word “doctor”). Ouranalyses show that four popular industrial MTsystems and two recent state-of-the-art aca-demic MT models are signiﬁcantly prone togender-biased translation errors for all testedtarget languages. Our data and code are pub-licly available at https://github.com/gabrielStanovsky/mt_gender.1IntroductionLearned models exhibit social bias when theirtraining data encode stereotypes not relevant forthe task, but the correlations are picked up any-way. Notable examples include gender biases invisual SRL (cooking is stereotypically done bywomen, construction workers are stereotypicallymen; Zhao et al., 2017), lexical semantics (“manis to computer programmer as woman is to home-maker”; Bolukbasi et al., 2016), and natural lan-guage inference (associating women with gossip-ing and men with guitars; Rudinger et al., 2017).In this work, we conduct the ﬁrst large-scalemultilingual evaluation of gender-bias in machinetranslation (MT), following recent small-scalequalitative studies which observed that online MTservices, such as Google Translate or MicrosoftTranslator, also exhibit biases, e.g., translatingnurses as females and programmers as males, re-gardless of context (Alvarez-Melis and Jaakkola,The doctor asked the nurse to help her in the procedureEl doctor le pidio a la enfermera que le ayudara con el procedimientoFigure 1: An example of gender bias in machine trans-lation from English (top) to Spanish (bottom).Inthe English source sentence, the nurse’s gender is un-known, while the coreference link with “her” identi-ﬁes the “doctor” as a female. On the other hand, theSpanish target sentence uses morphological featuresfor gender: “el doctor” (male), versus “la enfermer-a” (female). Aligning between source and target sen-tences reveals that a stereotypical assignment of genderroles changed the meaning of the translated sentence bychanging the doctor’s gender.2017; Font and Costa-Juss`a, 2019). Google Trans-late recently tried to mitigate these biases by al-lowing users to sometimes choose between gen-dered translations (Kuczmarski, 2018).As shown in Figure 1, we use data introducedby two recent coreference gender-bias studies: theWinogender (Rudinger et al., 2018), and the Wino-Bias (Zhao et al., 2018) datasets. Following theWinograd schema (Levesque, 2011), each instancein these datasets is an English sentence which de-scribes a scenario with human entities, who areidentiﬁed by their role (e.g., “the doctor” and “thenurse” in Figure 1), and a pronoun (“her” in theexample), which needs to be correctly resolvedto one of the entities (“the doctor” in this case).Rudinger et al. (2018) and Zhao et al. (2018) foundthat while human agreement on the task was high(roughly 95%), coreference resolution models of-ten ignore context and make socially biased pre-dictions, e.g., associating the feminine pronoun“her” with the stereotypically female “nurse.”We observe that for many target languages, afaithful translation requires a similar form of (at\f1680least implicit) gender identiﬁcation. In addition,in the many languages which associate betweenbiological and grammatical gender (e.g., most Ro-mance, Germanic, Slavic, and Semitic languages;Craig, 1986; Mucchi-Faina, 2005; Corbett, 2007),the gender of an animate object can be identiﬁedvia morphological markers. For instance, whentranslating our running example in Figure 1 toSpanish, a valid translation may be: “La doc-tora le pidio a la enfermera que le ayudara conel procedimiento,” which indicates that the doctoris a woman, by using a feminine sufﬁx inﬂection(“doctora”) and the feminine deﬁnite gendered ar-ticle (“la”). However, a biased translation systemmay ignore the given context and stereotypicallytranslate the doctor as male, as shown at the bot-tom of the ﬁgure.Following these observations, we design a chal-lenge set approach for evaluating gender bias inMT using a concatenation of Winogender andWinoBias.We devise an automatic translationevaluation method for eight diverse target lan-guages, without requiring additional gold trans-lations, relying instead on automatic measuresfor alignment and morphological analysis (Sec-tion 2). We ﬁnd that four widely used commercialMT systems and two recent state-of-the-art aca-demic models are signiﬁcantly gender-biased onall tested languages (Section 3). Our method andbenchmarks are publicly available, and are easilyextensible with more languages and MT models.2Challenge Set for Gender Bias in MTWe compose a challenge set for gender bias in MT(which we dub “WinoMT”) by concatenating theWinogender and WinoBias coreference test sets.Overall, WinoMT contains 3,888 instances, and isequally balanced between male and female gen-ders, as well as between stereotypical and non-stereotypical gender-role assignments (e.g., a fe-male doctor versus a female nurse). Additionaldataset statistics are presented in Table 1.We use WinoMT to estimate the gender-bias ofan MT model, M, in target-language L by per-forming following steps (exempliﬁed in Figure 1):(1) Translate all of the sentences in WinoMT intoL using M, thus forming a bilingual corpus of En-glish and the target language L.(2) Align between the source and target transla-tions, using fast align (Dyer et al., 2013), trainedon the automatic translations from from step (1).WinogenderWinoBiasWinoMTMale24015821826Female24015861822Neutral2400240Total72031683888Table 1:The coreference test sets and resultingWinoMT corpus statistics (in number of instances).We then map the English entity annotated in thecoreference datasets to its translation (e.g., alignbetween “the doctor” and “el doctor” in Figure 1).(3) Finally, we extract the target-side entity’sgender using simple heuristics over language-speciﬁc morphological analysis, which we per-form using off-the-shelf tools for each target lan-guage, as discussed in the following section.This process extracts the translated genders, ac-cording to M, for all of the entities in WinoMT,which we can then evaluate against the gold anno-tations provided by the original English dataset.This process can introduce noise into our eval-uation in steps (2) and (3), via wrong alignmentsor erroneous morphological analysis. In Section 3,we will present a human evaluation showing theseerrors are infrequent.3EvaluationIn this section, we brieﬂy describe the MT systemsand the target languages we use, our main results,and their human validation.3.1Experimental SetupMT systemsWe test six widely used MT mod-els, representing the state of the art in bothcommercial and academic research: (1) GoogleTranslate,1 (2) Microsoft Translator,2 (3) AmazonTranslate,3 (4) SYSTRAN,4 (5) the model of Ottet al. (2018), which recently achieved the best per-formance on English-to-French translation on theWMT’14 test set, and (6) the model of Edunovet al. (2018), the WMT’18 winner on English-to-German translation. We query the online API forthe ﬁrst four commercial MT systems, while forthe latter two academic models we use the pre-trained models provided by the Fairseq toolkit.51https://translate.google.com2https://www.bing.com/translator3https://aws.amazon.com/translate4http://www.systransoft.com5https://github.com/pytorch/fairseq\f1681Google TranslateMicrosoft TranslatorAmazon Translate∗SYSTRANAcc∆G∆SAcc∆G∆SAcc∆G∆SAcc∆G∆SES53.123.421.347.336.823.259.415.422.345.646.315.0FR63.66.426.744.736.429.755.217.724.945.044.09.4IT39.632.921.539.839.817.042.427.818.538.947.59.4RU37.736.811.436.842.18.539.734.79.237.344.19.3UK38.443.610.841.346.911.8–––28.922.412.9HE53.77.937.848.114.932.950.510.347.346.620.524.5AR48.543.716.147.348.313.449.838.519.047.049.45.3DE59.412.512.574.10.030.262.412.016.748.634.510.3Table 2: Performance of commercial MT systems on the WinoMT corpus on all tested languages, categorized bytheir family: Spanish, French, Italian, Russian, Ukrainian, Hebrew, Arabic, and German. Acc indicates overallgender accuracy (% of instances the translation had the correct gender), ∆G denotes the difference in performance(F1 score) between masculine and feminine scores, and ∆S is the difference in performance (F1 score) betweenpro-stereotypical and anti-stereotypical gender role assignments (higher numbers in the two latter metrics indicatestronger biases). Numbers in bold indicate best accuracy for the language across MT systems (row), and underlinednumbers indicate best accuracy for the MT system across languages (column). ∗Amazon Translate does not havea trained model for English to Ukrainian.Acc∆G∆SFR (Ott et al., 2018)49.42.616.1DE (Edunov et al., 2018)52.57.38.4Table 3: Performance of recent state-of-the-art aca-demic translation models from English to French andGerman. Metrics are the same as those in Table 2.Target languages and morphological analysisWe selected a set of eight languages with gram-matical gender which exhibit a wide range ofother linguistic properties (e.g., in terms of al-phabet, word order, or grammar), while still al-lowing for highly accurate automatic morpholog-ical analysis. These languages belong to four dif-ferent families: (1) Romance languages: Span-ish, French, and Italian, all of which have gen-dered noun-determiner agreement and spaCy mor-phological analysis support (Honnibal and Mon-tani, 2017). (2) Slavic languages (Cyrillic alpha-bet): Russian and Ukrainian, for which we usethe morphological analyzer developed by Korobov(2015). (3) Semitic languages: Hebrew and Ara-bic, each with a unique alphabet.For Hebrew,we use the analyzer developed by Adler and El-hadad (2006), while gender inﬂection in Arabiccan be easily identiﬁed via the ta marbuta charac-ter, which uniquely indicates feminine inﬂection.(4) Germanic languages: German, for which weuse the morphological analyzer developed by Al-tinok (2018).3.2ResultsOur main ﬁndings are presented in Tables 2 and 3.For each tested MT system and target language wecompute three metrics with respect to their abil-ity to convey the correct gender in the target lan-guage. Ultimately, our analyses indicate that alltested MT systems are indeed gender biased.First, the overall system Accuracy is calculatedby the percentage of instances in which the trans-lation preserved the gender of the entity fromthe original English sentence. We ﬁnd that mosttested systems across eight tested languages per-form quite poorly on this metric. The best per-forming model on each language often does notdo much better than a random guess for the correctinﬂection. An exception to this rule is the transla-tion accuracies on German, where three out of foursystems acheive their best performance. This maybe explained by German’s similarity to the Englishsource language (Hawkins, 2015).In Table 2, ∆G denotes the difference in per-formance (F1 score) between male and femaletranslations. Interestingly, all systems, except Mi-crosoft Translator on German, perform signiﬁ-cantly better on male roles, which may stem fromthese being more frequent in the training set.Perhaps most tellingly, ∆S measures the differ-\f1682ESFRITRUUKHEARDE2040608010067805244467660694654303335384457Accuracy (%)StereotypicalNon-StereotypicalFigure 2: Google Translate’s performance on gender translation on our tested languages. The performance on thestereotypical portion of WinoMT is consistently better than that on the non-stereotypical portion. The other MTsystems we tested display similar trends.Original+Adj∆ES53.163.5+10.4RU37.748.9+11.2UK38.442.9+4.5Table 4: Performance of Google Translate on Spanish,Russian, and Ukranian gender prediction accuracy (%correct) on the original WinoMT corpus, versus a mod-iﬁed version of the dataset where we add sterotypicalgender adjectives (see Section 3.3).ence in performance (F1 score) between stereo-typical and non-stereotypical gender role assign-ments, as deﬁned by Zhao et al. (2018) whouse statistics provided by the US Department ofLabor.6This metric shows that all tested sys-tems have a signiﬁcant and consistently better per-formance when presented with pro-stereotypicalassignments (e.g., a female nurse), while theirperformance deteriorates when translating anti-stereotypical roles (e.g., a male receptionist).For instance, Figure 2 depicts Google Trans-late absolute accuracies on stereotypical and non-stereotypical gender roles across all tested lan-guages. Other tested systems show similar trends.3.3Fighting Bias with BiasFinally, we tested whether we can affect thetranslations by automatically creating a versionof WinoMT with the adjectives “handsome” and“pretty” prepended to male and female entities, re-spectively. For example, the sentence in Figure 1will be converted to: “The pretty doctor asked thenurse to help her in the operation”. We are inter-ested in evaluating whether this “corrects” the pro-fession bias by mixing signals, e.g., while “doc-6https://www.bls.gov/cps/cpsaat11.htmtor” biases towards a male translation, “pretty”tugs the translation towards a female inﬂection.Our results show that this improved performancein some languages, signiﬁcantly reducing bias inSpanish, Russian, and Ukrainian (see Table 4).Admittedly, this is impractical as a general debi-asing scheme, since it assumes oracle coreferenceresolution, yet it attests to the relation betweencoreference resolution and MT, and serves as a fur-ther indication of gender bias in MT.3.4Human ValidationWe estimate the accuracy of our gender bias evalu-ation method by randomly sampling 100 instancesof all translation systems and target languages, an-notating each sample by two target-language na-tive speakers (resulting in 9,600 human annota-tions). Each instance conformed to a format sim-ilar to that used by our automatic gender detec-tion algorithm: human annotators were asked tomark the gender of an entity within a given target-language sentence. (e.g., see “el doctor” as high-lighted in the Spanish sentence in Figure 1). Byannotating at the sentence-level, we can accountfor both types of possible errors, i.e., alignmentand gender extraction.We compare the sentence-level human anno-tations to the output of our automatic method,and ﬁnd that the levels of agreement for all lan-guages and systems were above 85%, with anaverage agreement on 87% of the annotations.In comparison, human inter-annotator agreementwas 90%, due to noise introduced by several inco-herent translations.Our errors occur when language-speciﬁc id-iosyncrasies introduce ambiguity to the morpho-logical analysis. For example, gender for certainwords in Hebrew cannot be distinguished without\f1683Source[Target lang.] Predicted translationPhenomenonThe janitor does not like the bakerbecause she always messes up thekitchen.[ES] Al conserje no le gusta el panaderoporque ella siempre desordena la cocina.Biased translation, giving “baker” amale inﬂection, with a mismatched pro-noun reference.The janitor does not like the prettybaker because she always messes upthe kitchen.[ES] Al conserje no le gusta la panaderabonita porque ella siempre desordena lacocina.Adding a stereotypically female adjec-tive “ﬁxes” the translation.The counselor asked the guard a fewquestions and praised her for the goodwork.[FR] Le conseiller a pos´e quelques ques-tions `a la garde et l’a lou´ee pour le bontravail.French uses “garde” for both male andfemale guards, allowing for a more di-rect translation from English.Table 5: Examples of Google Translate’s output for different sentences in the WinoMT corpus. Words in blue,red, and orange indicate male, female and neutral entities, respectively.diacritics (e.g., the male and female versions of theword “baker” are spelled identically), and the con-tracted determiner in French and Italian (l’) is usedfor both masculine and feminine nouns. In ad-dition, some languages have only male or femaleinﬂections for professions which were stereotypi-cally associated with one of the genders, for exam-ple “sastre” (tailor) in Spanish or “soldat” (soldier)in French, which do not have female inﬂections.See Table 5 for detailed examples.4DiscussionRelated workThis work is most related to sev-eral recent efforts which evaluate MT throughthe use of challenge sets.Similarly to our useWinoMT, these works evaluate MT systems (ei-ther manually or automatically) on test sets whichare specially created to exhibit certain linguis-tic phenomena, thus going beyond the traditionalBLEU metric (Papineni et al., 2002). These in-clude challenge sets for language-speciﬁc idiosyn-crasies (Isabelle et al., 2017), discourse phenom-ena (Bawden et al., 2018), pronoun translation(M¨uller et al., 2018; Webster et al., 2018), orcoreference and multiword expressions (Burchardtet al., 2017).Limitations and future workWhile our workpresents the ﬁrst large-scale evaluation of genderbias in MT, it still suffers from certain limitationswhich could be addressed in follow up work. First,like some of the challenge sets discussed above,WinoMT is composed of synthetic English source-side examples. On the one hand, this allows fora controlled experiment environment, while, onthe other hand, this might introduce some artiﬁ-cial biases in our data and evaluation.Ideally,WinoMT could be augmented with natural “in thewild” instances, with many source languages, allannotated with ground truth entity gender. Sec-ond, similar to any medium size test set, it is clearthat WinoMT serves only as a proxy estimation forthe phenomenon of gender bias, and would prob-ably be easy to overﬁt. A larger annotated cor-pus can perhaps provide a better signal for train-ing. Finally, even though in Section 3.3 we showa very rudimentary debiasing scheme which relieson oracle coreference system, it is clear that thisis not applicable in a real-world scenario. Whilerecent research has shown that getting rid of suchbiases may prove to be very challenging (Elazarand Goldberg, 2018; Gonen and Goldberg, 2019),we hope that this work will serve as a ﬁrst step fordeveloping more gender-balanced MT models.5ConclusionsWe presented the ﬁrst large-scale multilingualquantitative evidence for gender bias in MT,showing that on eight diverse target languages,all four tested popular commercial systems andtwo recent state-of-the-art academic MT mod-els are signiﬁcantly prone to translate basedon gender stereotypes rather than more mean-ingful context.Our data and code are pub-liclyavailableathttps://github.com/gabrielStanovsky/mt_gender.AcknowledgmentsWe would like to thank Mark Yatskar, Iz Beltagy,Tim Dettmers, Ronan Le Bras, Kyle Richardson,Ariel and Claudia Stanovsky, and Paola Virga formany insightful discussions about the role genderplays in the languages evaluated in this work, aswell as the reviewers for their helpful comments.\f1684ReferencesMeni Adler and Michael Elhadad. 2006. An unsuper-vised morpheme-based HMM for Hebrew morpho-logical disambiguation. In ACL.Duygu Altinok. 2018. DEMorphy, German languagemorphological analyzer. CoRR, abs/1803.00902.David Alvarez-Melis and Tommi S. Jaakkola. 2017.A causal framework for explaining the predictionsof black-box sequence-to-sequence models.InEMNLP.Rachel Bawden, Rico Sennrich, Alexandra Birch, andBarry Haddow. 2018.Evaluating discourse phe-nomena in neural machine translation. In NAACL-HLT.Tolga Bolukbasi, Kai-Wei Chang, James Y. Zou,Venkatesh Saligrama, and Adam Tauman Kalai.2016. Man is to computer programmer as womanis to homemaker? debiasing word embeddings. InNIPS.Aljoscha Burchardt,Vivien Macketanz,Jon De-hdari, Georg Heigold, Jan-Thorsten Peter, andPhilip Williams. 2017.A linguistic evaluation ofrule-based, phrase-based, and neural mt engines.The Prague Bulletin of Mathematical Linguistics,108(1):159–170.Greville G Corbett. 2007. Gender and noun classes.Colette G Craig. 1986. Noun Classes and Categoriza-tion: Proceedings of a Symposium on Categoriza-tion and Noun Classiﬁcation, volume 7. John Ben-jamins Publishing Company.Chris Dyer, Victor Chahuneau, and Noah A. Smith.2013. A simple, fast, and effective reparameteriza-tion of ibm model 2. In HLT-NAACL.Sergey Edunov, Myle Ott, Michael Auli, and DavidGrangier. 2018. Understanding back-translation atscale. arXiv preprint arXiv:1808.09381.Yanai Elazar and Yoav Goldberg. 2018. Adversarialremoval of demographic attributes from text data. InEMNLP.Joel Escud´e Font and Marta R. Costa-Juss`a. 2019.Equalizing gender biases in neural machine trans-lation with word embeddings techniques.CoRR,abs/1901.03116.Hila Gonen and Yoav Goldberg. 2019. Lipstick on apig: Debiasing methods cover up systematic genderbiases in word embeddings but do not remove them.HLT-NAACL.John A Hawkins. 2015. A Comparative Typology ofEnglish and German: Unifying the Contrasts. Rout-ledge.Matthew Honnibal and Ines Montani. 2017. spaCy 2:Natural language understanding with Bloom embed-dings, convolutional neural networks and incremen-tal parsing. To appear.Pierre Isabelle, Colin Cherry, and George F. Foster.2017. A challenge set approach to evaluating ma-chine translation. In EMNLP.Mikhail Korobov. 2015. Morphological analyzer andgenerator for Russian and Ukrainian languages.In Mikhail Yu. Khachay, Natalia Konstantinova,Alexander Panchenko, Dmitry I. Ignatov, and Va-leri G. Labunets, editors, Analysis of Images, SocialNetworks and Texts, volume 542 of Communicationsin Computer and Information Science, pages 320–332. Springer International Publishing.James Kuczmarski. 2018.Reducing gender bias ingoogle translate.Hector J. Levesque. 2011. The Winograd schema chal-lenge. In AAAI Spring Symposium: Logical Formal-izations of Commonsense Reasoning.Angelica Mucchi-Faina. 2005. Visible or inﬂuential?language reforms and gender (in) equality. SocialScience Information, 44(1):189–215.Mathias M¨uller, Annette Rios, Elena Voita, and RicoSennrich. 2018. A large-scale test set for the evalu-ation of context-aware pronoun translation in neuralmachine translation. CoRR, abs/1810.02268.Myle Ott,Sergey Edunov,David Grangier,andMichael Auli. 2018. Scaling neural machine trans-lation. arXiv preprint arXiv:1806.00187.Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu. 2002. Bleu: a method for automatic eval-uation of machine translation. In ACL.Rachel Rudinger, Chandler May, and Benjamin VanDurme. 2017.Social bias in elicited natural lan-guage inferences. In EthNLP@EACL.Rachel Rudinger, Jason Naradowsky, Brian Leonard,and Benjamin Van Durme. 2018.Gender bias incoreference resolution. In NAACL-HLT.Kellie Webster, Marta Recasens, Vera Axelrod, and Ja-son Baldridge. 2018.Mind the gap: A balancedcorpus of gendered ambiguous pronouns. Transac-tions of the Association for Computational Linguis-tics, 6:605–617.Jieyu Zhao, Tianlu Wang, Mark Yatskar, Vicente Or-donez, and Kai-Wei Chang. 2017.Men also likeshopping: Reducing gender bias ampliﬁcation usingcorpus-level constraints. In EMNLP.Jieyu Zhao, Tianlu Wang, Mark Yatskar, Vicente Or-donez, and Kai-Wei Chang. 2018. Gender bias incoreference resolution:Evaluation and debiasingmethods. In NAACL-HLT.",
        "answer": "HE (Hebrew) exhibited the greatest bias in accuracy between stereotypical and non-stereotypical gender roles when using Google Translate, with an accuracy of 76% for stereotypical roles and 38% for non-stereotypical roles, resulting in a difference of 38 percentage points.",
        "space_key_index": 0,
        "metadata": {
            "format": "PDF 1.3",
            "title": "Evaluating Gender Bias in Machine Translation",
            "author": "Gabriel Stanovsky ; Noah A. Smith ; Luke Zettlemoyer",
            "subject": "P19-1 2019",
            "keywords": "",
            "creator": "LaTeX with hyperref package",
            "producer": "pdfTeX-1.40.17",
            "creationDate": "D:20190602234849Z",
            "modDate": "D:20190602234849Z",
            "trapped": "",
            "encryption": null
        }
    },
    {
        "question": "Which training data size from the Common Crawl resulted in the highest average accuracy across all GLUE tasks?",
        "context": "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processingand the 9th International Joint Conference on Natural Language Processing, pages 5360–5369,Hong Kong, China, November 3–7, 2019. c⃝2019 Association for Computational Linguistics5360Cloze-driven Pretraining of Self-attention NetworksAlexei Baevski, Sergey Edunov∗, Yinhan Liu∗, Luke Zettlemoyer, Michael AuliFacebook AI ResearchMenlo Park, CA and Seattle, WAAbstractWe present a new approach for pretraining abi-directional transformer model that providessigniﬁcant performance gains across a vari-ety of language understanding problems. Ourmodel solves a cloze-style word reconstructiontask, where each word is ablated and must bepredicted given the rest of the text. Experi-ments demonstrate large performance gains onGLUE and new state of the art results on NERas well as constituency parsing benchmarks,consistent with BERT. We also present a de-tailed analysis of a number of factors that con-tribute to effective pretraining, including datadomain and size, model capacity, and varia-tions on the cloze objective.1IntroductionLanguage model pretraining has recently beenshown to provide signiﬁcant performance gainsfor a range of challenging language understand-ing problems (Dai and Le, 2015; Peters et al.,2018; Radford et al., 2018).However, existingwork has either used unidirectional (left-to-right)language models (LMs) (Radford et al., 2018) orbi-directional (both left-to-right and right-to-left)LMs (BiLMs) where each direction is trained withan independent loss function (Peters et al., 2018).In this paper, we show that even larger perfor-mance gains are possible by jointly pretrainingboth directions of a large language-model-inspiredself-attention cloze model.Our bi-directional transformer architecture pre-dicts every token in the training data (Figure 1).We achieve this by introducing a cloze-style train-ing objective where the model must predict thecenter word given left-to-right and right-to-leftcontext representations.Our model separatelycomputes both forward and backward states with∗Equal contribution.<s>abc<s>Block1BlockNBlock1BlockNBlock1BlockNBlock1BlockNcombbFigure 1: Illustration of the model. Blocki is a standardtransformer decoder block. Green blocks operate left toright by masking future time-steps and blue blocks op-erate right to left. At the top, states are combined witha standard multi-head self-attention module whose out-put is fed to a classiﬁer that predicts the center token.a masked self-attention architecture, that closelyresembles a language model. At the top of the net-work, the forward and backward states are com-bined to jointly predict the center word. This ap-proach allows us to consider both contexts whenpredicting words and to incur loss for every wordin the training set, if the model does not assign ithigh likelihood.Experiments on the GLUE (Wang et al., 2018)benchmark show strong gains over the state of theart for each task, including a 9.1 point gain on RTEover Radford et al. (2018). These improvementsare consistent with, if slightly behind, BERT (De-vlin et al., 2018), which we will discuss in moredetail in the next section. We also show that itis possible to stack task-speciﬁc architectures forNER and constituency parsing on top of our pre-trained representations, and achieve new state-of-the-art performance levels for both tasks. We alsopresent extensive experimental analysis to better\f5361understand these results, showing that (1) hav-ing multiple sentences in each training exampleis crucial for many tasks; (2) pre-training contin-ues to improve performance with up to 18B tokensand would likely continue to improve with moredata; and ﬁnally (3) our novel cloze-driven train-ing regime is more effective than predicting leftand right tokens separately.2Related workThere has been much recent work on learningsentence-speciﬁc representations for language un-derstanding tasks. McCann et al. (2017) learn con-textualized word representations from a sequenceto sequence translation task and uses the represen-tations from the encoder network to improve a va-riety of language understanding tasks. Subsequentwork focused on language modeling pretrainingwhich has been shown to be more effective andwhich does not require bilingual data (Zhang andBowman, 2018).Our work was inspired by ELMo (Peters et al.,2018) and the generative pretraining (GPT) ap-proach of Radford et al. (2018). ELMo introduceslanguage models to pretrain word representationsfor downstream tasks including a novel mecha-nism to learn a combination of different layersin the language model that is most beneﬁcial tothe current task.GPT relies on a left to rightlanguage model and an added projection layerfor each downstream task without a task-speciﬁcmodel. Our approach mostly follows GPT, thoughwe show that our model also works well with anELMo module on NER and constituency parsing.The BERT model (Devlin et al., 2018) is atransformer encoder model that captures left andright context. There is signiﬁcant overlap betweentheir work and ours but there are also signiﬁcantdifferences: our model is a bi-directional trans-former language model that predicts every singletoken in a sequence.Our model has two uni-directional components encoding either the left orright context and both are combined to predict cen-ter words. BERT is also a transformer encoder thathas access to the entire input but this choice re-quires a special training regime. In particular, theymulti-task between predicting a subset of maskedinput tokens, similar to a denoising autoencoder,and a next sentence prediction task. In compar-ison, we optimize a single loss function that re-quires the model to predict each token of an in-put sentence given all surrounding tokens. We useall tokens as training targets and therefore extractlearning signal from every single token in the sen-tence and not just a subset. Melamud et al. (2016)follow a similar approach to ours by predictingthe center word but their architecture is based onLSTMs and we include the center word when weactually ﬁne-tune on downstream tasks.BERT tailors pretraining to capture dependen-cies between sentences via a next sentence predic-tion task as well as by constructing training exam-ples of sentence-pairs with input markers that dis-tinguish between tokens of the two sentences. Ourmodel is trained similarly to a classical languagemodel since we do not adapt the training exam-ples to resemble the end task data and we do notsolve a denoising task during training.Finally, BERT as well as Radford et al. (2018)consider only a single data source to pretraintheir models, either BooksCorpus (Radford et al.,2018), or BooksCorpus and additional Wikipediadata (Devlin et al., 2018), whereas our study ab-lates the effect of various amounts of training dataas well as different data sources.3Two tower modelOur cloze model represents a probability distribu-tion p(ti|t1, . . . , ti−1, ti+1, . . . , tn) for a sentencewith n tokens t1, . . . , tn.There are two self-attentional towers each consisting of N stackedblocks: the forward tower operates left-to-rightand the backward tower operates in the oppositedirection.To predict a token, we combine therepresentations of the two towers, as described inmore detail below, taking care that neither repre-sentation contains information about the currenttarget token.The forward tower computes the representationF li for token i at layer l based on the forward rep-resentations of the previous layer F l−1≤ivia self-attention; the backward tower computes represen-tation Bli based on information from the oppositedirection Bl−1≥i . When examples of uneven lengthare batched, one of the towers may not have anycontext at the beginning. We deal with this issueby adding an extra zero state over which the self-attention mechanism can attend.We pretrain on individual examples as they oc-cur in the training corpora (§5.1). For News Crawlthis is individual sentences while on Wikipedia,Bookcorpus, and Common Crawl examples are\f5362paragraph length. Sentences are prepended andappended with sample boundary markers < s >.3.1Block structureThe structure of the blocks follows most of thearchitectural choices described in Vaswani et al.(2017). Each block consists of two sub-blocks:the ﬁrst is a multi-head self-attention module withH = 16 heads for which we mask out any sub-sequent time-steps, depending on if we are deal-ing with the forward or backward tower. The sec-ond sub-block is a feed-forward module (FFN)of the form ReLU(W1X + b1)W2 + b2 whereW1 ∈Re×f, W1 ∈Rf×e. Different to Vaswaniet al. (2017) we apply layer normalization beforethe self-attention and FFN blocks instead of af-ter, as we ﬁnd it leads to more effective training.Sub-blocks are surrounded by a residual connec-tion (He et al., 2015).Position is encoded viaﬁxed sinusoidal position embeddings and we usea character CNN encoding of the input tokens forword-based models (Kim et al., 2016). Input em-beddings are shared between the two towers.3.2Combination of representationsThe forward and backward representations com-puted by the two towers are combined to pre-dict the ablated word. To combine them we usea self-attention module which is followed by anFFN block (§3.1). The output of the FFN blockf is projected by W into V classes represent-ing the types in the vocabulary: WT f to whicha softmax is applied. When the model predictstoken i, the input to the attention module areforward states F L1 . . . F Li−1 and backward statesBLi+1 . . . B:n where n is the length of the sequenceand L is the number of layers. We implement thisby masking BL≤i and F L≥i.The attention queryfor token i is a combination of F Li−1 and BLi+1.For the base model we sum the two representa-tions and for the larger models they are concate-nated. Keys and values are based on the forwardand backward states fed to the attention module.In summary, this module has access to informationabout the entire input surrounding the current tar-get token. During training, we predict every tokenin this way. The output of this module is fed to anoutput classiﬁer which predicts the center token.We use an adaptive softmax for the output classi-ﬁer (Grave et al., 2017) for the word based modelsand regular softmax for the BPE based models.abccombcombcombEmbedding of cEmbedding of bEmbedding of aFigure 2: Illustration of ﬁne-tuning for a downstreamtask. For classiﬁcation problems, output of the ﬁrstand last token is fed to a task-speciﬁc classiﬁer. Mask-ing for the ﬁnal combination layer (comb) is removedwhich results in representations based on all forwardand backward states (cf. Figure 1). The red dot-dashedarrows show connections that are masked during train-ing, but unmasked for ﬁne-tuning.While all states that contain information aboutthe current target word are masked in the ﬁnal self-attention block during training, we found it bene-ﬁcial to disable this masking when ﬁne tuning thepretrained model for downstream tasks. This is es-pecially true for tasks that label each token, suchas NER, as this allows the model to access the fullcontext including the token itself.4Fine-tuningWe use the following approach to ﬁne-tune thepretrained two tower model to speciﬁc down-stream tasks (Figure 2).Classiﬁcation and regression tasks.For sin-gle sentence classiﬁcation tasks, we consider thelanguage model outputs for the boundary tokens< s > which we add before the start and endof each sentence.The language model outputsare the representations f just before the ﬁnal soft-max layer (§3.2). The outputs are of dimensiond = 1024 and we concatenate them to project tothe number of classes C in the downstream taskwith W1 ∈RC×2d (Radford et al., 2018); we add abias term b ∈RC and initialize all weights as wellas the bias to zero. The output of the projectionis softmax-normalized and the model is optimizedwith cross-entropy for classiﬁcation tasks.Re-\f5363gression tasks such as the Semantic Textual Sim-ilarity benchmark (STS-B; Cer et al., 2017) useC = 1 and are trained with mean squared error.For tasks involving sentence-pairs, we concatenatethem and add a new separator token < sep > be-tween them. We add the output of this token to theﬁnal projection W2 ∈RC×3d.Structured prediction tasks.For named entityrecognition and parsing we use task-speciﬁc archi-tectures which we ﬁne-tune together with the lan-guage model but with different learning rate. Thearchitectures are detailed in the respective resultssections.The input to the architectures are theoutput representations of the pretrained languagemodel.No Masking.For ﬁne-tuning, we found it bene-ﬁcial to remove masking of the current token inthe ﬁnal layer that pools the output of the twotowers. This is different than in the actual pre-training. It is important to have access to informa-tion about the token to be classiﬁed for token levelclassiﬁcation tasks such as NER but we also foundthis to perform better for sentence classiﬁcationtasks. In practice, we completely disable maskingin the combination layer so that it operates overall forward and backward states. However, dis-abling masking below the combination layer doesnot perform well.Optimization.During ﬁne-tuning we use largerlearning rates for the new parameters, that is W1,W2, b or the task-speciﬁc architecture, comparedto the pretrained model. For GLUE tasks, we doso by simply scaling the output of the languagemodel before the W1 and W2 projections by afactor of 16. For structured prediction tasks, weexplicitly use different learning rates for the pre-trained model and the task-speciﬁc parameters.We ﬁne tune with the Adam optimizer (Kingmaand Ba, 2015).For GLUE tasks, we disabledropout in the language model and add 0.1 dropoutbetween language model output and the ﬁnal out-put projection; for structured prediction tasks, weuse 0.3 at all levels (within the pretrained model,within the task-speciﬁc architecture, and on theweights connecting them). In all settings, we use abatch size of 16 examples. We use a cosine sched-ule to linearly warm up the learning rate from 1e-07 to the target value over the ﬁrst 10% of train-ing steps, and then anneal the learning rate to 1e-06, following the cosine curve for the remainingsteps. For GLUE tasks, we tuned the learning ratefor each task and chose the best value over threesettings: 1e-04, 5e-05 and 3e-05. For structuredprediction tasks, we tuned on the pairs of learningrate, see the results section for details. For GLUEtasks, we train three seeds for each learning ratevalue for three epochs and choose the model af-ter each epoch that performs best on the validationset. For structured prediction tasks, we train for upto 25 epochs and stop if the validation loss doesnot improve over the previous epoch.5Experimental setup5.1Datasets for pretrainingWe train the two tower model on several datasets.Common Crawl.We consider various subsetsof Common Crawl which is web data. We fol-low the same pre-processing as Grave et al. (2018)which is based on the May 2017 Common Crawldump.This setup add 20 copies of EnglishWikipedia resulting in about 14% of the ﬁnaldataset to be Wikipedia. We subsample up to 18Btokens. All experiments use Common Crawl sub-sampled to 9B tokens, except §6.4.News Crawl.We use up to 4.5B words of En-glish news web data distributed as part of WMT2018 (Bojar et al., 2018).BooksCorpus + Wikipedia.This is similar tothe training data used by BERT which comprisesthe BooksCorpus (Zhu et al., 2015) of about 800Mwords plus English Wikipedia data of 2.5B words.5.2Pretraining hyper-parametersWe adapt the transformer implementation avail-able in the fairseq toolkit to our two tower archi-tecture (Ott et al., 2019). For hyper-parameter andoptimization choices we mostly follow Baevskiand Auli (2018). Our experiments consider threemodel sizes shown in Table 1: There are two CNNinput models in a base and large conﬁguration aswell as a Byte-Pair-Encoding based model (BPE;Sennrich et al., 2016). The CNN models have un-constrained input vocabulary, and an output vo-cabulary limited to 1M most common types forthe large model, and 700K most common typesfor the base model. CNN models use an adap-tive softmax in the output: the head band containsthe 60K most frequent types with dimensionality\f5364ModelParametersUpdatesBlocksFFNDimAttn Heads(ﬁnal layer)Query formation(ﬁnal layer)Train time(days)CNN Base177M600K6409612Sum6CNN Large330M1M12409632Concat10BPE Large370M1M12409632Concat4.5Table 1: Hyper-parameters for our models. Parameter count excludes the (adaptive) softmax layer. Train time asmeasured on 128 Volta GPUs for the CNN models and 64 Volta GPUs for the BPE model.1024, followed by a 160K band with dimension-ality 256. The remaining types have dimensional-ity 64; there are 480K types for the small modeland 780K for the large model. The BPE modeluses a vocabulary of 55K types and we share inputand output embeddings in a ﬂat softmax with di-mension 1024 (Inan et al., 2016; Press and Wolf,2017). The BPE vocabulary was constructed byapplying 30K merge operations over the trainingdata, then applying the BPE code to the trainingdata and retaining all types occurring at least threetimes.Every setup uses model dimensionaltiy d =1024 with H = 16 attention heads for all but theﬁnal attention layer. Model based on character in-puts use character embedding size 128 and we ap-ply six ﬁlters of size 1x128, 2x256, 3x384, 4x512,5x512, 6x512 followed by a single highway layer.The models are trained with model and attentiondropout rate of 0.1 and ReLU dropout rate of 0.05.Different to Vaswani et al. (2017) we use Nes-terov’s accelerated gradient method (Sutskeveret al., 2013) with a momentum of 0.99 and werenormalize gradients if their norm exceeds 0.1(Pascanu et al., 2013). The learning rate is lin-early warmed up from 10−7 to 1 for 16K steps andthen annealed using a cosine learning rate sched-ule with a single phase to 0.0001 (Loshchilov andHutter, 2016).We run experiments on DGX-1 machines with8 NVIDIA V100 GPUs and machines are inter-connected by Inﬁniband. We also use the NCCL2library and the torch.distributed package for inter-GPU communication. We train models with 16-bit ﬂoating point precision, following Ott et al.(2018). The BPE model trains much faster thanthe character CNN models (Table 1).6Results6.1GLUEFirst, we conduct experiments on the generallanguage understanding evaluation benchmark(GLUE; Wang et al., 2018) and present a shortoverview of the tasks. More information can befound in Wang et al. (2018). There are two single-sentence classiﬁcation tasks: First, the Corpus ofLinguistic Acceptability (CoLA; Warstadt et al.,2018) is a binary task to judge sentence grammat-icality; evaluation is in terms of the Matthews cor-relation coefﬁcient (mcc). Second, the StanfordSentiment Treebank (SST-2; Socher et al., 2013)requires to judge if movie reviews have positive ornegative sentiment; evaluation is in terms of accu-racy (acc).There are three tasks assessing sentence sim-ilarity: The Microsoft Research Paragraph Cor-pus (MRPC; Dolan and Brockett, 2015) and theQuora Question Pairs benchmark (QQP); we eval-uate in terms of F1. The Semantic Textual Similar-ity Benchmark (STS-B; Cer et al., 2017) requirespredicting a similarity score between 1 and 5 for asentence pair; we report the Spearman correlationcoefﬁcient (scc).Finally, there are four natural language infer-ence tasks: the Multi-Genre Natural Language In-ference (MNLI; Williams et al., 2018), the Stan-ford Question Answering Dataset (QNLI; Ra-jpurkar et al., 2016), the Recognizing Textual En-tailment (RTE; Dagan et al., 2006, Bar Haim et al.,2006, Ciampiccolo et al., 2007 Bentivogli et al.,2009). We exclude the Winograd NLI task fromour results similar to Radford et al. (2018); De-vlin et al. (2018) and report accuracy. For MNLIwe report both matched (m) and mismatched (mm)accuracy on test.We also report an average over the GLUE met-rics. This ﬁgure is not comparable to the aver-age on the ofﬁcial GLUE leaderboard since we ex-clude Winograd and do not report MRPC accuracy\f5365CoLA(mcc)SST-2(acc)MRPC(F1)STS-B(scc)QQP(F1)MNLI-(m/mm)(acc)QNLI(acc)RTE(acc)AvgOpenAI GPT45.491.382.380.070.382.1/81.488.156.075.2CNN Base53.193.681.382.270.582.5/82.289.564.677.7CNN Large52.894.683.783.471.784.3/83.889.863.778.6BPE Large51.894.083.084.270.682.9/82.289.365.178.1GPT on STILTs47.293.187.784.870.180.7/80.687.269.177.8BERTBASE52.193.588.985.871.284.6/83.490.166.479.6BERTLARGE60.594.989.386.572.186.7/85.991.170.181.9Table 2: Test results as per the GLUE evaluation server. The average column does not include the WNLI test set.mcc = Matthews correlation, acc = Accuracy, scc = Spearman correlation.STS-B Pearson correlation as well as QQP accu-racy.Table 2 shows results for three conﬁgurationsof our approach (cf. Table 1). The BPE modelhas more parameters than the CNN model butdoes not perform better in aggregate, however, it isfaster to train. All our models outperform the uni-directional transformer (OpenAI GPT) of Radfordet al. (2018), however, our model is about 50%larger than their model. We also show results forSTILTs (Phang et al., 2018) and BERT (Devlinet al., 2018). Our CNN base model performs aswell as STILTs in aggregate, however, on sometasks involving sentence-pairs, STILTs performsmuch better (MRPC, RTE); there is a similar trendfor BERT.STILTs adds another ﬁne-tuning step on an-other downstream task which is similar to the ﬁ-nal task. The technique is equally applicable toour approach. Training examples for our modelare Common Crawl paragraphs of arbitrary length.We expect that tailoring training examples for lan-guage model pretraining to the end tasks to signif-icantly improve performance. For example, BERTtrains on exactly two sentences while as we trainon entire paragraphs.6.2Structured PredictionWe also evaluated performance on two structuredpredictions tasks, NER and constituency parsing.For both problems, we stacked task-speciﬁc archi-tectures from recent work on top of our pretrainedtwo tower models. We evaluate two ways of stack-ing: (1) ELMo-style, where the pretrained mod-els are not ﬁne-tuned but are linearly combined atdifferent depths, and (2) with ﬁne-tuning, wherewe set different learning rates for the task-speciﬁcModeldev F1test F1ELMoBASE95.792.2CNN Large + ELMo96.493.2CNN Large + ﬁne-tune96.993.5BERTBASE96.492.4BERTLARGE96.692.8Table 3: CoNLL-2003 Named Entity Recognition re-sults. Test result was evaluated on parameter set withthe best dev F1.Modeldev F1test F1ELMoBASE95.295.1CNN Large + ELMo95.195.2CNN Large + ﬁne-tune95.595.6Table 4: Penn Treebank Constituency Parsing results.Test result was evaluated on parameter set with the bestdev F1.layers but otherwise update all of the parametersduring the task-speciﬁc training.6.2.1Named Entity RecognitionWe evaluated span-level F1 performance on theCoNLL 2003 Named Entity Recognition (NER)task, where spans of text must be segmented andlabeled as Person, Organization, Location, or Mis-cellaneous. We adopted the NER architecture inPeters et al. (2018), a biLSTM-CRF, with two mi-nor modiﬁcations: (1) instead of two layers of biL-STM, we only used one, and (2) a linear projectionlayer was added between the token embedding andbiLSTM layer. We did grid search on the pairs oflearning rate, and found that projection-biLSTM-\f5366CoLA(mcc)SST-2(acc)MRPC(F1)STS-B(scc)QQP(F1)MNLI-m(acc)QNLI(acc)RTE(acc)Avgcloze55.192.988.388.387.282.386.566.480.9bilm50.092.486.687.186.181.784.066.479.3cloze + bilm52.693.288.987.987.282.186.165.580.4Table 5: Different loss functions on the development sets of GLUE (cf. Table 2). Results are based on the CNNbase model (Table 1)CRF with 1E-03 and pretrained language modelwith 1E-05 gave us the best result.Table 3 shows the results, with comparisonto previous published ELMoBASE results (Peterset al., 2018) and the BERT models. Both of ourstacking methods outperform the previous state ofthe art, but ﬁne tuning gives the biggest gain.6.2.2Constituency ParsingWe also report parseval F1 for Penn Treebank con-stituency parsing. We adopted the current state-of-the-art architecture (Kitaev and Klein, 2018). Weagain used grid search for learning rates and num-ber of layers in parsing encoder, and used 8E-04for language model ﬁnetuning, 8E-03 for the pars-ing model parameters, and two layers for encoder.Table 4 shows the results. Here, ﬁne tuning isrequired to achieve gains over the previous stateof the art, which used ELMo embeddings.6.3Objective functions for pretrainingThe two-tower model is trained to predict the cur-rent token given representations of the entire leftand right context (cloze). Next we compare thischoice to two alternatives:First, Peters et al.(2018) train two language models operating left-to-right and right-to-left to predict the next wordfor each respective direction. We change the two-tower model to predict the next word using the in-dividual towers only and remove the combinationmodule on top of the two towers (bilm); however,we continue to jointly train the two towers.Second, we combine the cloze loss with thebilm loss to obtain a triplet loss which trains themodel to predict the current word given both leftand right context, as well as just right or left con-text. The latter is much harder than the cloze losssince less context is available and therefore gradi-ents for the bilm loss are much larger: the clozemodel achieves perplexity of about 4 while as forthe bilm it is 27-30, depending on the direction.This results in the bilm loss dominating the triplet562M1.1B2.25B4.5B9B18B8080.58181.5Train data tokensAvg. GLUE scoreAverage GLUE scoreFigure 3: Average GLUE score with different amountsof Common Crawl data for pretraining.loss and we found that scaling the bilm term by afactor of 0.15 results in better performance.Table 5 shows that the cloze loss performs sig-niﬁcantly better than the bilm loss and that com-bining the two loss types does not improve overthe cloze loss by itself.We conjecture that in-dividual left and right context prediction tasksare too different from center word prediction andthat their learning signals are not complementaryenough.6.4Domain and amount of training dataNext we investigate how much pretraining beneﬁtsfrom larger training corpora and how the domainof the data inﬂuences end-task performance.Figure 3 shows that more training data can sig-niﬁcantly increase accuracy. We train all modelswith the exact same hyper-parameter settings onCommon Crawl data using the CNN base archi-tecture for 600K updates. We train on up to 18BCommon Crawl tokens and the results suggest thatmore training data is likely to further increase per-formance.Table 6 shows a breakdown into individual\f5367train data(M tok)CoLA(mcc)SST-2(acc)MRPC(F1)STS-B(scc)QQP(F1)MNLI-m(acc)QNLI(acc)RTE(acc)Avgccrawl56252.592.988.288.387.181.785.763.379.9112555.593.186.188.487.181.985.765.280.4225055.492.487.788.487.282.286.266.980.8450056.693.087.388.687.082.086.265.780.8900055.192.988.388.387.282.386.566.480.91800056.393.188.088.887.282.386.368.481.3newscrawl56250.992.881.478.284.979.182.055.775.6112551.493.083.082.385.279.782.853.976.4225054.892.983.582.885.480.482.454.877.1450053.993.683.883.185.580.483.654.277.3BWiki - sent330053.591.686.486.286.982.386.963.879.7BWiki - blck330050.691.986.487.186.881.986.260.478.9Table 6: Effect of different domains and amount of data for pretraining on the on the development sets of GLUE(cf. Table 2). Results are based on the CNN base model (Table 1).GLUE tasks. For pretraining on Common Crawl,CoLA and RTE beneﬁt most from additional train-ing data. The same table also shows results forNews Crawl which contains newswire data. Thisdata generally performs less well than CommonCrawl, even on MRPC which is newswire.Alikely reason is that News Crawl examples are in-dividual sentences of 23 words on average whichcompares to several sentences or 50 words on av-erage for Common Crawl. Mutli-sentence trainingexamples are more effective for end-tasks basedon sentence pairs, e.g., there is a 14 point accu-racy gap on RTE between News Crawl and Com-mon Crawl with 4.5B tokens. More News Crawldata is most beneﬁcial for CoLA and STS-B.We also experiment with BooksCorpus (Zhuet al., 2015) as well as English Wikipedia, similarto Devlin et al. (2018). Examples in BooksCorpusare a mix of individual sentences and paragraphs;examples are on average 36 tokens. Wikipedia ex-amples are longer paragraphs of 66 words on av-erage. To reduce the effect of training on exam-ples of different lengths, we adopted the followingstrategy: we concatenate all training examples intoa single string and then crop blocks of 512 consec-utive tokens from this string. We train on a batchof these blocks (BWiki - blck). It turns out that thisstrategy did not work better compared to our exist-ing strategy of simply using the data as is (BWiki -sent). BooksCorpus and Wikipedia performs verywell on QNLI and MNLI but less well on othertasks.In summary, more data for pretraining improvesperformance, keeping everything else equal. Alsopretraining on corpora that retains paragraphstructure performs better than individual sen-tences.7ConclusionWe presented a pretraining architecture based on abi-directional transformer model that predicts ev-ery token in the training data. The model is trainedwith a cloze-style objective and predicts the centerword given all left and right context.Results on the GLUE benchmark show largegains over Radford et al. (2018) for each task,while experiments with model stacking set newstate of the art performance levels for parsing andnamed entity recognition. We also did extensiveexperimental analysis to better understand theseresults, showing that (1) having multiple sentencesin each training example is crucial for many tasks;(2) pre-training continues to improve performanceup to 18B tokens and would likely continue to im-prove with more data; and ﬁnally (3) our novelcloze-driven training regime is more effective thanpredicting left and right tokens separately.In future work, we will investigate variationsof our architecture. In particular, we had initialsuccess sharing the parameters of the two towerswhich allows training much deeper models with-out increasing the parameter count.\f5368ReferencesAlexei Baevski and Michael Auli. 2018. Adaptive in-put representations for neural language modeling.arXiv, abs/1809.10853.Luisa Bentivogli, Peter Clark, Ido Dagan, and DaniloGiampiccolo. 2009.The ﬁfth pascal recognizingtextual entailment challenge. In Proc. of TAC.Ondˇrej Bojar, Christian Federmann, Mark Fishel,Yvette Graham, Barry Haddow, Matthias Huck,Philipp Koehn, and Christof Monz. 2018.Find-ings of the 2018 conference on machine translation(WMT18). In Proc. of WMT.Daniel M. Cer, Mona T. Diab, Eneko Agirre, I˜nigoLopez-Gazpio, and Lucia Specia. 2018. Semeval-2017 task 1: Semantic textual similarity - multilin-gual and cross-lingual focused evaluation. In Proc.of SemEval.Ido Dagan, Oren Glickman, and Bernardo Magnini.2006.The pascal recognizing textual entailmentchallenge.Machine learning challenges, evaluat-ing predictive uncertainty, visual object classiﬁca-tion, and recognizing textual entailment, pages 177–190.AndrewM.DaiandQuocV.Le.2015.Semi-supervisedsequencelearning.arXiv,abs/1511.01432.Jacob Devlin, Ming-Wei Chang, Kenton Lee, andKristina Toutanova. 2018. Bert: Pre-training of deepbidirectional transformers for language understand-ing. CoRR, abs/1810.04805.William B. Dolan and Chris Brockett. 2005. Automati-cally constructing a corpus of sentential paraphrases.In Proc. of IWP.Danilo Giampiccolo, Bernardo Magnini, Ido Dagan,and Bill Dolan. 2007.The pascal recognizingtextual entailment challenge.Proc. of the ACL-PASCAL workshop on textual entailment and para-phrasing.Edouard Grave, Piotr Bojanowski, Prakhar Gupta, Ar-mand Joulin, and Tomas Mikolov. 2018. Learningword vectors for 157 languages. In Proc. of LREC.Edouard Grave, Armand Joulin, Moustapha Ciss´e,David Grangier, and Herv´e J´egou. 2017. Efﬁcientsoftmax approximation for gpus. In Proc. of ICML.Roy Bar Haim, Ido Dagan, Bill Dolan, Lisa Ferro,Danilo Giampiccolo, Bernardo Magnini, and IdanSzpektor. 2006. The pascal recognising textual en-tailment challenge.Kaiming He, Xiangyu Zhang, Shaoqing Ren, and JianSun. 2015.Deep Residual Learning for ImageRecognition. In Proc. of CVPR.Hakan Inan, Khashayar Khosravi, and Richard Socher.2016.Tying word vectors and word classiﬁers:A loss framework for language modeling.arXiv,abs/1611.01462.Yoon Kim, Yacine Jernite, David Sontag, and Alexan-der M Rush. 2016. Character-aware neural languagemodels. In AAAI, pages 2741–2749.Diederik P. Kingma and Jimmy Ba. 2015. Adam: AMethod for Stochastic Optimization.In Proc. ofICLR.Nikita Kitaev and Dan Klein. 2018. Constituency pars-ing with a self-attentive encoder. In Proc. of ACL.Ilya Loshchilov and Frank Hutter. 2016.SGDR:stochastic gradient descent with restarts.arXiv,abs/1608.03983.Bryan McCann, James Bradbury, Caiming Xiong, andRichard Socher. 2017. Learned in translation: Con-textualized word vectors. In Proc. of NIPS.Oren Melamud, Jacob Goldberger, and Ido Dagan.2016. context2vec: Learning generic context em-bedding with bidirectional lstm. In Proc. of CoNLL.Myle Ott, Sergey Edunov, Alexei Baevski, AngelaFan, Sam Gross, Nathan Ng, David Grangier, andMichael Auli. 2019.fairseq: A fast, extensibletoolkit for sequence modeling. In Proc. of NAACLSystem Demonstrations.Myle Ott,Sergey Edunov,David Grangier,andMichael Auli. 2018. Scaling neural machine trans-lation. In Proc. of WMT.Razvan Pascanu, Tomas Mikolov, and Yoshua Bengio.2013. On the difﬁculty of training recurrent neuralnetworks. In Proc. of ICML.Matthew E Peters, Mark Neumann, Mohit Iyyer, MattGardner, Christopher Clark, Kenton Lee, and LukeZettlemoyer. 2018. Deep contextualized word rep-resentations. In Proc. of ACL.Jason Phang, Thibault Fevry, and Samuel R. Bowman.2018. Sentence encoders on stilts: Supplementarytraining on intermediate labeled-data tasks. arXiv,abs/1811.01088.Oﬁr Press and Lior Wolf. 2017. Using the output em-bedding to improve language models. In Proc. ofEACL.AlecRadford,KarthikNarasimhan,TimSali-mans,and Ilya Sutskever. 2018.Improvinglanguage understanding by generative pre-training.https://s3-us-west-2.amazonaws.com/openai-assets/research-covers/language-unsupervised/language_understanding_paper.pdf.Pranav Rajpurkar, Jian Zhang, Konstantin Lopyrev,and Percy Liang. 2016.Squad: 100, 000+ ques-tions for machine comprehension of text.arXiv,abs/1606.05250.\f5369Rico Sennrich, Barry Haddow, and Alexandra Birch.2016. Neural machine translation of rare words withsubword units. In Proc. of ACL.Richard Socher, Alex Perelygin, Jean Wu, JasonChuang, Christopher D. Manning, Andrew Ng, andChristopher Potts. 2013.Recursive deep modelsfor semantic compositionality over a sentiment tree-bank. In Proc. of EMNLP.Ilya Sutskever, James Martens, George E. Dahl, andGeoffrey E. Hinton. 2013. On the importance of ini-tialization and momentum in deep learning. In Proc.of ICML.Ashish Vaswani, Noam Shazeer, Niki Parmar, JakobUszkoreit, Llion Jones, Aidan N. Gomez, LukaszKaiser, and Illia Polosukhin. 2017. Attention Is AllYou Need. In Proc. of NIPS.Alex Wang, Amanpreet Singh, Julian Michael, FelixHill, Omer Levy, and Samuel R. Bowman. 2018.GLUE: A multi-task benchmark and analysis plat-form for natural language understanding.arXiv,abs/1804.07461.Alex Warstadt, Amanpreet Singh, and Sam Bow-man. 2018.Corpus of linguistic acceptability.https://nyu-mll.github.io/CoLA.Adina Williams, Nikita Nangia, and Samuel R Bow-man. 2018. A broad-coverage challenge corpus forsentence understanding through inference. In Proc.of NAACL.Kelly W. Zhang and Samuel R. Bowman. 2018. Lan-guage modeling teaches you more syntax than trans-lation does: Lessons learned through auxiliary taskanalysis. arXiv, abs/1809.10040.Yukun Zhu, Ryan Kiros, Richard S. Zemel, RuslanSalakhutdinov, Raquel Urtasun, Antonio Torralba,and Sanja Fidler. 2015. Aligning books and movies:Towards story-like visual explanations by watchingmovies and reading books. arXiv, abs/1506.06724.",
        "answer": "The 18,000 million tokens (M tok) training data size from the Common Crawl resulted in the highest average accuracy of 81.3 across all GLUE tasks.",
        "space_key_index": 2,
        "metadata": {
            "format": "PDF 1.3",
            "title": "Cloze-driven Pretraining of Self-attention Networks",
            "author": "Alexei Baevski ; Sergey Edunov ; Yinhan Liu ; Luke Zettlemoyer ; Michael Auli",
            "subject": "D19-1 2019",
            "keywords": "",
            "creator": "LaTeX with hyperref package",
            "producer": "pdfTeX-1.40.18",
            "creationDate": "D:20190829113438Z",
            "modDate": "D:20190829113438Z",
            "trapped": "",
            "encryption": null
        }
    },
    {
        "question": "Is the Seq2Seq model shown to produce longer or shorter sentences when compared to human responses?",
        "context": "Proceedings of the 2018 EMNLP Workshop SCAI: The 2nd Int’l Workshop on Search-Oriented Conversational AI, pages 87–92Brussels, Belgium, October 31, 2018. c⃝2018 Association for Computational LinguisticsISBN 978-1-948087-75-987Retrieve and Reﬁne:Improved Sequence Generation Models For DialogueJason Weston, Emily Dinan and Alexander H. MillerFacebook AI Researchjase@fb.com, edinan@fb.com, ahm@fb.comAbstractSequence generation models for dialogue areknown to have several problems: they tend toproduce short, generic sentences that are un-informative and unengaging. Retrieval modelson the other hand can surface interesting re-sponses, but are restricted to the given retrievalset leading to erroneous replies that cannot betuned to the speciﬁc context. In this work wedevelop a model that combines the two ap-proaches to avoid both their deﬁciencies: ﬁrstretrieve a response and then reﬁne it – the ﬁnalsequence generator treating the retrieval as ad-ditional context. We show on the recent CON-VAI2 challenge task our approach producesresponses superior to both standard retrievaland generation models in human evaluations.1IntroductionSequencegenerationmodelslikeSeq2Seq(Sutskever et al., 2014) are increasingly popularfor tasks such as machine translation (MT) andsummarization,where generation is suitablyconstrained by the source sentence.However,obtaining good performance on dialogue tasks,where the context still allows many interpreta-tions, remains an open problem despite muchrecent work (Serban et al., 2016).Several au-thors report the issue that they produce short,generic sentences containing frequent words –the so-called “I don’t know” problem – as thatresponse can work as a reply in many instances,but is uninformative and unengaging.Retrievalmodels (Ji et al., 2014) do not have this problem,but instead either produce engaging responses orelse completely erroneous ones which they cannotProceedings of the 2018 EMNLP Workshop SCAI: The2nd International Workshop on Search-Oriented Conversa-tional AI 978-1-948087-75-9tune to the speciﬁc context, as they can onlyproduce a valid reply if it is in the retrieval set.In this work we propose a Retrieve and Reﬁnemodel to gain the advantages of both methods,and avoid both their disadvantages. Models thatproduce an initial prediction and then reﬁne it aregrowing in traction in NLP. They have been usedin MT and summarization either for reﬁnement ofinitial predictions (Junczys-Dowmunt and Grund-kiewicz, 2017; Niehues et al., 2016; Novak et al.,2016; Xia et al., 2017; Grangier and Auli, 2017)or combining with retrieval (Gu et al., 2017; Caoet al., 2018), as well as for sentence correctionor reﬁnement without context (Guu et al., 2017;Schmaltz et al., 2017). There is little work in ap-plying these methods to dialogue; one work we areaware of has been done concurrently with ours isPandey et al. (2018). The usefulness of our ap-proach is shown with detailed experiments on theConvAI2 dataset1 which is a chit-chat task to getto know the other speaker’s proﬁle, obtaining gen-erations superior to both retrieval and sequencegeneration models in human evaluations.2Retrieve and ReﬁneThe model we propose in this work is remark-ably straight-forward: we take a standard gener-ative model and concatenate the output of a re-trieval model to its usual input, and then generateas usual, training the model under this setting.For the generator, we use a standard Seq2Seqmodel: a 2-layer LSTM with attention. For theretriever, we use the Key-Value Memory Network(Miller et al., 2016) already shown to perform wellfor this dataset (Zhang et al., 2018), which attendsover the dialogue history, to learn input and candi-date retrieval embeddings that match using cosinesimilarity. The top scoring utterance is provided1http://convai.io/\f88as input to our Seq2Seq model in order to reﬁneit, prepended with a special separator token. Forboth models we use the code available in ParlAI2.At test time the retriever retrieves candidates fromthe training set.To train our model we ﬁrst precompute the re-trieval result for every dialogue turn in the train-ing set, but instead of using the top ranking resultswe rerank the top 100 predictions of each by theirsimilarity to the label (in embedding space). Fol-lowing Guu et al. (2017) this should help avoid theproblem of the reﬁnement being too far away fromthe original retrieval. We then append the cho-sen utterances to the input sequences used to trainSeq2Seq.We refer to our model as RetrieveN-Reﬁne, or RetNRef for short.We also considertwo variants of the model in the following that wefound improve the results.Use Retriever MoreIn our vanilla model, wenoticed there was not enough attention being paidto the retrieval utterance by the generator. As theinput to Seq2Seq is the dialogue history concate-nated with the retrieval utterance, truncating thehistory is one way to pay more attention to the re-trieval. In particular for the ConvAI2 dataset weclip the initial proﬁle sentences at the start of thedialogue, forcing the model to more strongly relyon the retriever which still has them.3 We refer tothis modiﬁcation as RetrieveNReﬁne+.Fix Retrieval Copy ErrorsOur model learns tosometimes ignore the retrieval (when it is bad),sometimes use it partially, and other times sim-ply copy it. However, when it is mostly copiedbut only changes a word or two, we observed itmade mistakes more often than not, leading toless meaningful utterances.We thus also con-sider a variant that exactly copies the retrievalif the model generates with large word over-lap (we chose >60%).Otherwise, we leavethe generation untouched.4We refer to this asRetrieveNReﬁne++.2http://parl.ai3Architectural changes might also deal with this issue,e.g. treating the two inputs as independent sources to do at-tention over, but we take the simplest possible approach here.4Other approaches might also help with this problem suchas using an explicit copy mechanism or to use BPE tokeniza-tion (Fan et al., 2017), but we leave those for future work.RetNRef Retrieval MethodPPLNone (Vanilla Seq2Seq)31.4Random label32.0Memory Network31.8True label’s neighbor25.9True label9.2Table 1: Perplexity on the ConvAI2 task test set withdifferent types of retriever for RetNRef, see text.3ExperimentsWe conduct experiments on the recent ConvAI2challenge dataset which uses a modiﬁed versionof the PersonaChat dataset (Zhang et al., 2018)(larger, and with different processing). The datasetconsists of conversations between crowdworkerswho were randomly paired and asked to act thepart of a given persona (randomly assigned from1155 possible personas, created by another set ofworkers), chat naturally, and get to know eachother during the conversation. There are around160,000 utterances in around 11,000 dialogues,with 2000 dialogues for validation and test, whichuse non-overlapping personas.3.1Automatic Evaluation and AnalysisPerplexityDialogue is known to be notoriouslyhard to evaluate with automated metrics (Liu et al.,2016). In contrast to machine translation, there ismuch less constraint on the output with many validanswers with little word overlap, e.g. there aremany answers to “what are you doing tonight?”.Nevertheless many recent papers report perplexityresults in addition to human judgments. For the re-trieve and reﬁne case, perplexity evaluation is par-ticularly ﬂawed: if the retrieval points the model toa response that is very different from (but equallyvalid as) the true response, the model might focuson reﬁning that and get poor perplexity.We therefore test our model by consideringvarious types of retrieval methods: (i) the bestperforming existing retriever model, the MemoryNetwork approach from Zhang et al. (2018) (re-trieving from the training set), (ii) a retriever thatreturns a random utterance from the training set,(iii) the true label given in the test set, and (iv) theclosest nearest neighbor from the training set ut-terances to the true label, as measured by the em-bedding space of the Memory Network retrievermodel. While (iii) and (iv) cannot be used in a de-ployed system as they are unknown, they can be\f89WordCharRare Word %Methodcntcnt<100<1kSeq2Seq11.740.50.4%5.8%RetNRef11.840.41.1%6.9%RetNRef+12.145.01.7%10.1%RetNRef++12.748.12.3%10.9%MemNet13.154.54.0%15.3%Human13.054.63.0%11.5%Table 2: Output sequence statistics for the methods.Seq2Seq generates shorter sentences with more com-mon words than humans, which RetNRef alleviates.Method<30%30-60%60-80%>80%Seq2Seq56%34%7%3%RetNRef41%38%13%8%RetNRef+26%20%12%42%RetNRef++26%20%0%53%Table 3:Word overlap between retrieved and gener-ated utterances in RetNRef, and between Seq2Seq andthe Memory Network retriever (ﬁrst row).used as a sanity check: a useful retrieve and reﬁneshould improve perplexity if given these as input.We also compare to a standard Seq2Seq model, i.e.no retrieval.The results are given in Table 1. They show thatthe RetNRef model can indeed improve perplexitywith label neighbors or the label itself. However,surprisingly there is almost no difference betweenusing no retrieval, random labels or our best re-triever. The RetNRef++ model – that truncatesthe dialogue history and focuses more on the re-trieval utterance – does even worse in terms ofperplexity: 48.4 using the Memory Network re-triever. However, poor perplexity does not meanhuman judgments of the generated sequences willnot improve; in fact we will see that they do in thenext section. How to automatically evaluate thesekinds of models still remains an open problem.Word StatisticsAnother way to measure thesalience of a generation model is to compare it tohuman utterances in terms of word statistics. Weanalyze the word statistics of our models in Table2. Seq2Seq models are known to produce shortsentences with more common words than humans.The statistics on the ConvAI2 dataset bear this out,where the Seq2Seq model responses have lowerword and character counts and use fewer rarewords than the human responses. The RetNRefmodel (using the Memory Network retriever, re-trieving from the training set) makes some im-provements in this regard, e.g. doubling the useof rare words (with frequency less than 100) andsmaller gains for words with frequency less than1000, but are still not close to human statistics.The RetNRef++ model which boosts the use ofthe retrieval does better in this regard, making thestatistics much closer to human ones. Of coursethese metrics do not measure whether the utter-ances are semantically coherent, but it is encour-aging to see a model using rare words as withoutthis we believe it is hard for it to be engaging.Table 3 compares the word overlap between re-trieved and generated sentences in the RetNRefvariants in order to measure if RetNRef is eitherignoring the retriever, or else paying too much at-tention to and copying it. As comparison, the ﬁrstrow also shows the overlap between the retrieverand vanilla Seq2Seq which does not retrieve atall. The results show that RetNRef++ has >80%word overlap with the retriever output around half(53%) of the time, whereas Seq2Seq and RetNRefvery rarely overlap with the retriever (3% and 8%of the time respectively have >80% overlap). Thisshows that our improved model RetNRef++ doesuse the retriever, but can also generate novel con-tent when it wants to, which a standard retrievercannot.3.2Evaluation by Human Judgement ScoresFollowing the protocol in Zhang et al. (2018), weasked humans to conduct short dialogues with ourmodels (100 dialogues each of 10-20 turns, so 600dialogues in total), and then measure the engag-ingness, consistency, and ﬂuency (all scored outof 5) as well as to try to detect the persona thatthe model is using, given the choice between thatand a random persona. Consistency measures thecoherence of the dialogue, e.g. “I have a dog” fol-lowed by “I have no pets” is not consistent.The results are given in Table 4. They showengagingness scores superior to Seq2Seq for allRetNRef variants, and with RetNRef++ slightlyoutperforming the retriever which it conditionson.Importantly however, it maintains this per-formance whilst still being able to generate textwhich a retrieval model cannot. It also performswell in the other metrics, although like the Mem-ory Network model, it is weaker at using the per-sona than Seq2Seq.Seq2Seq is inferior to the\f90MethodEngagingnessFluencyConsistencyPersonaSeq2Seq (PPL)2.70(1.17)3.50(1.37)3.90(1.37)0.90(0.29)Seq2Seq (100 epochs)2.76(1.15)3.53(1.14)3.84(1.38)0.85(0.35)Memory Network3.66(1.26)3.83(1.26)3.61(1.36)0.73(0.44)RetrieveNReﬁne2.94(1.26)3.65(1.28)3.72(1.32)0.90(0.30)RetrieveNReﬁne+3.50(1.33)3.63(1.13)3.55(1.33)0.71(0.45)RetrieveNReﬁne++3.80(1.18)3.74(1.19)3.80(1.40)0.65(0.47)Table 4: Human Evaluation scores for the models,scoring ﬂuency, engagingness, consistency and persona detec-tion, with standard deviation in parentheses. We consider engagingness to be the most important metric.Comparison (A vs. B)Win RateA WinsB WinsTiep-valueRetrieveNReﬁne++ vs. Memory Network54.5%3402845720.027RetrieveNReﬁne++ vs. Seq2Seq53.7%5714922030.016RetrieveNReﬁne++(retrieved) vs.Seq2Seq53.8%29024987RetrieveNReﬁne++(generated) vs.Seq2Seq53.6%281243116RetrieveNReﬁne+ vs. Memory Network51.63%492461243RetrieveNReﬁne+ vs. Human30.13%6916014Seq2Seq vs. Human26.84%6216922Table 5: A/B testing by humans comparing model pairs, reporting win rates for A over B (excluding ties).Person 1hey , george here . lets be friendsyeah. well, i wish you luck there. we bought a cute 2 story house.Person 2hi george , i’m regina . do you enjoy dance ?nice , i don’t think i have ever left ohio.Seq2Seqi do not but i do have a lot of time to dancei am sorry. i am so scared of twins.MemNethello george my name is pinki am from mississippi . just moved back here from austin texasRetNRef+i do. i enjoy dance.i am from tennessee. just moved here from austin texas.Person 1drinking coffee? what time is it there?thank you for that , you are what you believe ?Person 2830 pm haha my dad is a construction workerlook energy isn’t physical , only spiritualso he works really late nightsSeq2Seqi am a big guy so i can help youi am not sure what that meansMemNetyep . moonlight is amazing but northerndo you do any sports ? swimming helps me keep my energy up.light grab you tooRetNRef+oh wow, that is a long timedo you do any sports ? swimming helps me keep my energy upTable 6: Example dialogues (left) where RetNRef outperforms MemNet, and (right) where RetNRef outperformsSeq2Seq – by either paying attention to the retriever or not. The ﬁrst two rows are the previous two dialogue turnsby Person 1 & 2, the following rows are the predictions for the next utterance of Person 1 by the various models.Memory Network Retriever in terms of engage-ment, in line with previous results. We also triedovertraining the Seq2Seq for 100 epochs insteadof early stopping by validation on perplexity as itmay overﬁt training sentences and act more as aretriever, but this did not help.Some example dialogues of the RetNRef++model performing well (as scored by the evalua-tors) are shown in Tables 7 and 8. Longer sen-tences from the bot (person 2) with more nu-anced entity information typically come from at-tending to the retriever, whereas the generator canalso produce shorter replies independent of the re-triever that ﬁt the context well. There are still is-sues however, such as repeated phrases by the gen-erator, and some tendency to copy the speakingpartner’s phrases that could be improved.3.3A/B Testing by HumansTo compute a statistically more meaningful test,and to evaluate models more clearly against eachother, we also tested models by pairing themagainst each other (different to the protocol pre-viously used for this dataset). We took human-human paired dialogues from the test set, up to arandomly chosen turn, and then computed the re-sponse of two rival models. The resulting dialoguehistory and the two choices are given to a third an-notator to evaluate and asked which model is best;they can also choose “unsure”. We collected over1000 such examples, with each conversation beingevaluated twice. The results are given in Table 5.\f91Persona 1Persona 2I am relatively tall.I like to play baseball.I like mexican food.I love eating seafood.I drive a subaru legacy.I enjoy learning new languages.My dog’s name is Drunky.I’m currently going for a marketing degree.I can touch my toes with my nose.I want to design ads in the future.[PERSON 1:] I’m driving to the mexican place tonight for dinner, but my Subaru is at the rental shop.[PERSON 2:] Yummy. I love mexican food, but I never eat vegetables[PERSON 1:] Oh, I do, I think that’s why i’m so tall![PERSON 2:] how tall are you? I do not... I enjoy studying languages.[PERSON 1:] I’m 6 foot, a lot taller than my dog, Drunky.[PERSON 2:] I am sorry to hear that. I want to be 6 foot tall.[PERSON 1:] Do you have any talents? I can reach my toes using my nose.[PERSON 2:] Cool! I listen to audiobooks and speak one asian language. you like sushi? I do.[PERSON 1:] Oh sushi is my next favorite, after Mexican. What kind of car do you have?[PERSON 2:] I have a Nissan Sentra. I love it.Table 7: Example dialog between a human (Person 1) and the RetNRef++ model (Person 2). References to nevereating vegetables, listening to audiobooks and speaking one asian language and owning a Nissan Sentra appearedin the conditioned retrieved sentences, improving the overall engaging quality of the dialogue.Persona 1Persona 2I am a lacto-ovo vegetarian.I have brown hair.I like to hike.I am Latina.I have red hair.My mother works for special needs clients..My favorite drink is sprite.I am a healer.I have a pet parrot named Tasha.I love my family.[PERSON 1:] I dont know about you but I love sprite. Its my favorite.[PERSON 2:] I like dr pepper a lot, but sprite is my second favorite.[PERSON 1:] Sprites great! I take it with me every day on my hikes.[PERSON 2:] I bet. I love to go to the water[PERSON 1:] Ya that sounds like a great time. I go with my pet parrot Tasha when I go[PERSON 2:] that is a good idea. I wish I had a parrot.[PERSON 1:] Ya its fun. As a pet owner you learn to love animals; im even a lactoovo vegetarian now[PERSON 2:] I love animals. I am vegan so I eat vegan food.[PERSON 1:] Sounds like me :D im vegan, im ginger, and i love sprite[PERSON 2:] I love animals. I am vegan so I eat a lot of it.Table 8: Example dialog between a human (Person 1) and the RetNRef++ model (Person 2). References toDr. Pepper and wishing to have a parrot appeared in the conditioned retrieved sentences, improving the overallengaging quality of the dialogue. There are still issues however, such as repeated phrases by the generator, failureto use the persona adequately, and some tendency to copy the speaking partner’s phrases that could be improved.RetrieveNReﬁne obtains statistically signiﬁcantwins over the retriever Memory Network modeland the generator Seq2Seq model using a binomialtwo-tailed test, with win rates ∼54%. Breakingdown the wins between when RetNRef++ exactlycopies the retrieval utterance vs. generates we seethat it chooses them about equally, with wins aboutequal in both cases. This shows it can effectivelylearn when to choose the retrieval utterance (whenit is good), and when to ignore it and generate in-stead (when it is bad). Table 6, which shows ex-ample outputs of our model, illustrates this.RetNRef+ sometimes loses out when makingsmall changes to the retrieved text, for exampleit made changes to “i once broke my nose try-ing to peak in on a jazz concert !” by replacingpeak with glacier. Recall that RetNRef++ ﬁxesthis problem by exactly copying the retrieved textwhen there is insigniﬁcant word overlap with thegenerated text; as such, it has a correspondinglylarger win rate against Memory Networks (54.5%versus 51.63%).We also computed a small sample of A/B testsdirectly against humans rather than models, andagain see the win rate is higher for RetNRef.4ConclusionIn conclusion, we showed that retrieval modelscan be successfully used to improve generationmodels in dialogue, helping them avoid commonissues such as producing short sentences with fre-quent words that ultimately are not engaging. Our\f92RetNRef++ model has similar statistics to humanutterances and provides more engaging conversa-tions according to human judgments.Future work should investigate improved waysto incorporate retrieval in generation, both avoid-ing the heuristics we used here to improve per-formance, and seeing if more sophisticated ap-proaches than concatenation plus attention im-prove the results, for example by more clearlytreating the inputs as independent sources, ortraining the models jointly.ReferencesZiqiang Cao, Wenjie Li, Sujian Li, and Furu Wei.2018. Retrieve, rerank and rewrite: Soft templatebased neural summarization. In Proceedings of the56th Annual Meeting of the Association for Compu-tational Linguistics (Volume 1: Long Papers), vol-ume 1, pages 152–161.Angela Fan, David Grangier, and Michael Auli. 2017.Controllable abstractive summarization.arXivpreprint arXiv:1711.05217.David Grangier and Michael Auli. 2017. Quickedit:Editing text & translations via simple delete actions.arXiv preprint arXiv:1711.04805.Jiatao Gu, Yong Wang, Kyunghyun Cho, and Vic-tor OK Li. 2017.Search engine guided non-parametric neural machine translation.arXivpreprint arXiv:1705.07267.KelvinGuu,TatsunoriBHashimoto,YonatanOren, and Percy Liang. 2017.Generating sen-tences by editing prototypes.arXiv preprintarXiv:1709.08878.Zongcheng Ji, Zhengdong Lu, and Hang Li. 2014. Aninformation retrieval approach to short text conver-sation. arXiv preprint arXiv:1408.6988.Marcin Junczys-Dowmunt and Roman Grundkiewicz.2017.An exploration of neural sequence-to-sequence architectures for automatic post-editing.arXiv preprint arXiv:1706.04138.Chia-Wei Liu, Ryan Lowe, Iulian V Serban, MichaelNoseworthy, Laurent Charlin, and Joelle Pineau.2016. How not to evaluate your dialogue system:An empirical study of unsupervised evaluation met-rics for dialogue response generation. arXiv preprintarXiv:1603.08023.Alexander Miller, Adam Fisch, Jesse Dodge, Amir-Hossein Karimi, Antoine Bordes, and Jason We-ston. 2016.Key-value memory networks fordirectlyreadingdocuments.arXivpreprintarXiv:1606.03126.Jan Niehues, Eunah Cho, Thanh-Le Ha, and AlexWaibel. 2016.Pre-translation for neural machinetranslation. arXiv preprint arXiv:1610.05243.Roman Novak, Michael Auli, and David Grangier.2016. Iterative reﬁnement for machine translation.arXiv preprint arXiv:1610.06602.Gaurav Pandey, Danish Contractor, Vineet Kumar, andSachindra Joshi. 2018. Exemplar encoder-decoderfor neural conversation generation.In Proceed-ings of the 56th Annual Meeting of the Associationfor Computational Linguistics (Volume 1: Long Pa-pers), volume 1, pages 1329–1338.Allen Schmaltz, Yoon Kim, Alexander M Rush,and Stuart M Shieber. 2017.Adapting sequencemodels for sentence correction.arXiv preprintarXiv:1707.09067.Iulian Vlad Serban, Ryan Lowe, Laurent Charlin, andJoelle Pineau. 2016.Generative deep neural net-works for dialogue: A short review. arXiv preprintarXiv:1611.06216.Ilya Sutskever, Oriol Vinyals, and Quoc V Le. 2014.Sequence to sequence learning with neural net-works. In Advances in neural information process-ing systems, pages 3104–3112.Yingce Xia, Fei Tian, Lijun Wu, Jianxin Lin, Tao Qin,Nenghai Yu, and Tie-Yan Liu. 2017. Deliberationnetworks: Sequence generation beyond one-pass de-coding. In Advances in Neural Information Process-ing Systems, pages 1782–1792.Saizheng Zhang, Emily Dinan, Jack Urbanek, ArthurSzlam, Douwe Kiela, and Jason Weston. 2018. Per-sonalizing dialogue agents: I have a dog, do youhave pets too? arXiv preprint arXiv:1801.07243.",
        "answer": "Shorter.",
        "space_key_index": 1,
        "metadata": {
            "format": "PDF 1.3",
            "title": "Retrieve and Refine: Improved Sequence Generation Models For Dialogue",
            "author": "Jason Weston ; Emily Dinan ; Alexander Miller",
            "subject": "SCAI 2018",
            "keywords": "",
            "creator": "LaTeX with hyperref package",
            "producer": "pdfTeX-1.40.18",
            "creationDate": "D:20180904035547Z",
            "modDate": "D:20180904035547Z",
            "trapped": "",
            "encryption": null
        }
    }
]